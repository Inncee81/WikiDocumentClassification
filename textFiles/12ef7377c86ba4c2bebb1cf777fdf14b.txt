













Fundamental theorem of calculus - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Fundamental_theorem_of_calculus";
		var wgTitle = "Fundamental theorem of calculus";
		var wgAction = "view";
		var wgArticleId = "19468696";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 281821928;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Fundamental theorem of calculus

From Wikipedia, the free encyclopedia

Jump to: navigation, search 


Topics in calculus



Fundamental theorem
Limits of functions
Continuity
Vector calculus
Matrix calculus
Mean value theorem



Differentiation



Product rule
Quotient rule
Chain rule
Change of variables
Implicit differentiation
Taylor's theorem
Related rates
List of differentiation identities



Integration



Lists of integrals
Improper integrals
Integration by:
parts, disks, cylindrical
shells, substitution,
trigonometric substitution,
partial fractions, changing order



The fundamental theorem of calculus specifies the relationship between the two central operations of calculus: differentiation and integration.
The first part of the theorem, sometimes called the first fundamental theorem of calculus, shows that an indefinite integration[1] can be reversed by a differentiation. The first part is also important because it guarantees the existence of antiderivatives for continuous functions. [2]
The second part, sometimes called the second fundamental theorem of calculus, allows one to compute the definite integral of a function by using any one of its infinitely many antiderivatives. This part of the theorem has invaluable practical applications, because it markedly simplifies the computation of definite integrals.
The first published statement and proof of a restricted version of the fundamental theorem was by James Gregory (1638–1675)[3]. Isaac Barrow (1630–1677) proved the first completely general version of the theorem, while Barrow's student Isaac Newton (1643–1727) completed the development of the surrounding mathematical theory. Gottfried Leibniz (1646–1716) systematized the knowledge into a calculus for infinitesimal quantities.




Contents


1 Physical intuition
2 Geometric intuition
3 Formal statements

3.1 First part
3.2 Corollary
3.3 Second part


4 Examples
5 Proof of the first part
6 Proof of the corollary
7 Proof of the Second Part
8 Generalizations
9 See also
10 Notes
11 References
12 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Physical intuition
Intuitively, the theorem simply states that the sum of infinitesimal changes in a quantity over time (or some other quantity) add up to the net change in the quantity.
To comprehend this statement, we will start with an example. Suppose a particle travels in a straight line with its position, x, given by x(t) where t is time and x(t) means that x is a function of t. The derivative of this function is equal to the infinitesimal change in quantity, dx, per infinitesimal change in time, dt (of course, the derivative itself is dependent on time). Let us define this change in distance per change in time as the velocity v of the particle. In Leibniz's notation:



Rearranging this equation, it follows that:



By the logic above, a change in x (or Δx) is the sum of the infinitesimal changes dx. It is also equal to the sum of the infinitesimal products of the derivative and time. This infinite summation is integration; hence, the integration operation allows the recovery of the original function from its derivative. As one can reasonably infer, this operation works in reverse as we can differentiate the result of our integral to recover the original.

[edit] Geometric intuition




The area shaded in light red stripes can be computed as h times ƒ(x), or if we knew the function A(x), it could be estimated as A(x + h) − A(x). These two values are approximately equal, particularly for small h.


Suppose we are given a smooth continuous function y = ƒ(x), and have plotted its graph as a curve. Then for each value of x, intuitively it makes sense that there is a corresponding area function A(x), representing the area beneath the curve between 0 and x. We may not know a "formula" for the function A(x), but intuitively we understand that it is simply the area under the curve.
Now suppose we wanted to compute the area under the curve between x and x + h. We could compute this area by finding the area between 0 and x + h, then subtracting the area between 0 and x. In other words, the area of this “sliver” would be A(x + h) − A(x).
There is another way to estimate the area of this same sliver. Multiply h by ƒ(x) to find the area of a rectangle that is approximately the same size as this sliver. In fact, it makes intuitive sense that for very small values of h, the approximation will become very good.
At this point we know that A(x + h) − A(x) is approximately equal to ƒ(x)·h, and we intuitively understand that this approximation becomes better as h grows smaller. In other words, ƒ(x)·h ≈ A(x + h) − A(x), with this approximation becoming an equality as h approaches 0 in the limit.
Divide both sides of this equation by h. Then we have



As h approaches 0, we recognized that the right hand side of this equation is simply the derivative A’(x) of the area function A(x). The left-hand side of the equation simply remains ƒ(x), since no h is present.
We have shown informally that ƒ(x) = A’(x). In other words, the derivative of the area function A(x) is the original function ƒ(x). Or, to put it another way, the area function is simply the antiderivative of the original function.
What we have shown is that, intuitively, computing the derivative of a function and “finding the area” under its curve are "opposite" operations. This is the crux of the Fundamental Theorem of Calculus. The bulk of the theorem's proof is devoted to showing that the area function A(x) exists in the first place.

[edit] Formal statements
There are two parts to the Fundamental Theorem of Calculus. Loosely put, the first part deals with the derivative of an antiderivative, while the second part deals with the relationship between antiderivatives and definite integrals.

[edit] First part
This part is sometimes referred to as the First Fundamental Theorem of Calculus.[4]
Let ƒ be a continuous real-valued function defined on a closed interval [a, b]. Let F be the function defined, for all x in [a, b], by



Then, F is continuous on [a, b], differentiable on the open interval (a, b), and



for all x in (a, b).

[edit] Corollary
The fundamental theorem is often employed to compute the definite integral of a function ƒ for which an antiderivative g is known. Specifically, if ƒ is a real-valued continuous function on [a, b], and g is an antiderivative of ƒ in [a, b], then



The corollary assumes continuity on the whole interval. This result is strengthened slightly in the following theorem.

[edit] Second part
This part is sometimes referred to as the Second Fundamental Theorem of Calculus.[5]
Let ƒ be a real-valued function defined on a closed interval [a, b]. Suppose that ƒ admits an antiderivative g on [a, b], that is, a function such that for all x in [a, b],



(when an antiderivative g exists, then there are infinitely many antiderivatives for ƒ, obtained by adding to g an arbitrary constant. Also, by the first part of the theorem, antiderivatives of ƒ always exist when ƒ is continuous).
If ƒ is integrable on [a, b] then



Notice that the Second part is somewhat stronger than the Corollary because it does not assume that ƒ is continuous.
Note. The second part is also known as Newton-Leibniz Axiom.

[edit] Examples
As an example, suppose you need to calculate



Here, f(x) = x2 and we can use  as the antiderivative. Therefore:



Or, more generally, suppose you need to calculate



Here, f(t) = t3 and we can use  as the antiderivative. Therefore:



But this result could have been found much more easily as




[edit] Proof of the first part
For a given f(t), define the function F(x) as



For any two numbers x1 and x1 + Δx in [a, b], we have



and



Subtracting the two equations gives



It can be shown that


(The sum of the areas of two adjacent regions is equal to the area of both regions combined.)

Manipulating this equation gives



Substituting the above into (1) results in



According to the mean value theorem for integration, there exists a c in [x1, x1 + Δx] such that



Substituting the above into (2) we get



Dividing both sides by Δx gives


Notice that the expression on the left side of the equation is Newton's difference quotient for F at x1.

Take the limit as Δx → 0 on both sides of the equation.



The expression on the left side of the equation is the definition of the derivative of F at x1.



To find the other limit, we will use the squeeze theorem. The number c is in the interval [x1, x1 + Δx], so x1 ≤ c ≤ x1 + Δx.
Also,  and 
Therefore, according to the squeeze theorem,



Substituting into (3), we get



The function f is continuous at c, so the limit can be taken inside the function. Therefore, we get



which completes the proof.
(Leithold et al, 1996)

[edit] Proof of the corollary
Let    with ƒ continuous on [a, b]. If g is an antiderivative of ƒ, then g and F have the same derivative, by the first part  of the theorem. It follows that there is a number c such that F(x) = g(x) + c, for all x in [a, b]. Letting x = a,



which means c = − g(a). In other words F(x) = g(x) − g(a), and so




[edit] Proof of the Second Part
This is a limit proof by Riemann sums.
Let f be continuous on the interval [a, b], and let F be an antiderivative of f. Begin with the quantity



Let there be numbers

x1, ..., xn

such that



It follows that



Now, we add each F(xi) along with its additive inverse, so that the resulting quantity is equal:



The above quantity can be written as the following sum:



Next we will employ the mean value theorem. Stated briefly,
Let F be continuous on the closed interval [a, b] and differentiable on the open interval (a, b). Then there exists some c in (a, b) such that



It follows that



The function F is differentiable on the interval [a, b]; therefore, it is also differentiable and continuous on each interval xi-1. Therefore, according to the mean value theorem (above),



Substituting the above into (1), we get



The assumption implies F'(ci) = f(ci). Also, xi − xi − 1 can be expressed as Δx of partition i.







A converging sequence of Riemann sums. The numbers in the upper right are the areas of the grey rectangles. They converge to the integral of the function.


Notice that we are describing the area of a rectangle, with the width times the height, and we are adding the areas together. Each rectangle, by virtue of the Mean Value Theorem, describes an approximation of the curve section it is drawn over. Also notice that Δxi does not need to be the same for any value of i, or in other words that the width of the rectangles can differ. What we have to do is approximate the curve with n rectangles. Now, as the size of the partitions get smaller and n increases, resulting in more partitions to cover the space, we will get closer and closer to the actual area of the curve.
By taking the limit of the expression as the norm of the partitions approaches zero, we arrive at the Riemann integral. We know that this limit exists because f was assumed to be integrable. That is, we take the limit as the largest of the partitions approaches zero in size, so that all other partitions are smaller and the number of partitions approaches infinity.
So, we take the limit on both sides of (2). This gives us



Neither F(b) nor F(a) is dependent on ||Δ||, so the limit on the left side remains F(b) - F(a).



The expression on the right side of the equation defines an integral over f from a to b. Therefore, we obtain



which completes the proof.
It almost looks like the first part of the theorem follows directly from the second, because the equation    where g is an antiderivative of ƒ, implies that    has the same derivative as g, and therefore F ′ = ƒ. This argument only works if we already know that ƒ has an antiderivative, and the only way we know that all continuous functions have antiderivatives is by the first part of the Fundamental Theorem[6]. For example if ƒ(x) = e−x2, then ƒ has an antiderivative, namely



and there is no simpler expression for this function. It is therefore important not to interpret the second part of the theorem as the definition of the integral. Indeed, there are many functions that are integrable but lack antiderivatives. Conversely, many functions that have antiderivatives are not Riemann integrable (see Volterra's function).

[edit] Generalizations
We don't need to assume continuity of ƒ on the whole interval. Part I of the theorem then says: if ƒ is any Lebesgue integrable function on [a, b] and x0 is a number in [a, b] such that ƒ is continuous at x0, then



is differentiable for x = x0 with F'(x0) = ƒ(x0). We can relax the conditions on ƒ still further and suppose that it is merely locally integrable. In that case, we can conclude that the function F is differentiable almost everywhere and F'(x) = ƒ(x) almost everywhere. On the real line this statement is equivalent to Lebesgue's differentiation theorem. These results remain true for the Henstock–Kurzweil integral which allows a larger class of integrable functions (Bartle 2001, Thm. 4.11).
In higher dimensions Lebesgue's differentiation theorem generalizes the Fundamental theorem of calculus by stating that for almost every x, the average value of a function ƒ over a ball of radius r centered at x will tend to ƒ(x) as r tends to 0.
Part II of the theorem is true for any Lebesgue integrable function ƒ which has an antiderivative F (not all integrable functions do, though). In other words, if a real function F on [a, b] admits a derivative ƒ(x) at every  point x of [a, b] and if this derivative ƒ is Lebesgue integrable on [a, b], then

    Rudin (1987, th. 7.21)

This result may fail for continuous functions F that admit a derivative ƒ(x) at almost every point x, as the example of the Cantor function shows. But the result remains true if F is absolutely continuous: in that case, F admits a derivative ƒ(x) at almost every point x and, as in the formula above, F(b) − F(a) is equal to the integral of ƒ on [a, b].
The conditions of this theorem may again be relaxed by considering the integrals involved as Henstock-Kurzweil integrals. Specifically, if a continuous function F(x) admits a derivative ƒ(x) at all but countably many points, then ƒ(x) is Henstock-Kurzweil integrable and F(b) − F(a) is equal to the integral of ƒ on [a, b]. The difference here is that the integrability of ƒ does not need to be assumed. (Bartle 2001, Thm. 4.7)
The version of Taylor's theorem which expresses the error term as an integral can be seen as a generalization of the Fundamental Theorem.
There is a version of the theorem for complex functions: suppose U is an open set in C and ƒ : U → C is a function which has a holomorphic antiderivative F on U. Then for every curve γ : [a, b] → U, the curve integral can be computed as



The fundamental theorem can be generalized to curve and surface integrals in higher dimensions and on manifolds.
One of the most powerful statements in this direction is Stokes' theorem: Let M be an oriented piecewise smooth manifold of dimension n and let ω be an n−1 form that is a compactly supported differential form on M of class C1. If ∂M denotes the boundary of M with its induced orientation, then



Here  is the exterior derivative, which is defined using the manifold structure only.
The theorem is often used in situations where M is an embedded oriented submanifold of some bigger manifold on which the form ω is defined.

[edit] See also




Mathematics portal




Differintegral


[edit] Notes

^ More exactly, the theorem deals with definite integration with variable upper limit and arbitrarily selected lower limit. This particular kind of definite integration allows us to compute one of the infinitely many antiderivatives of a function (except for those which do not have a zero). Hence, it is almost equivalent to indefinite integration, defined by most authors as an operation which yields any one of the possible antiderivatives of a function, including those without a zero.
^ Spivak, Michael (1980), Calculus (2nd ed.), Houstan, Texas: Publish or Perish Inc. 
^ See, e.g., Marlow Anderson, Victor J. Katz, Robin J. Wilson, Sherlock Holmes in Babylon and Other Tales of Mathematical History, Mathematical Association of America, 2004, p. 114.
^ Apostol 1967, §5.1
^ Apostol 1967, §5.3
^ Spivak, Michael (1980), Calculus (2nd ed.), Houston, Texas: Publish or Perish Inc. 


[edit] References

Apostol, Tom M. (1967), Calculus, Vol. 1: One-Variable Calculus with an Introduction to Linear Algebra (2nd ed.), New York: John Wiley & Sons, ISBN 978-0-471-00005-1 .
Bartle, Robert (2001), A Modern Theory of Integration, AMS, ISBN 0821808451 .
Larson, Ron; Edwards, Bruce H.; Heyd, David E. (2002), Calculus of a single variable (7th ed.), Boston: Houghton Mifflin Company .
Leithold, L. (1996), The calculus of a single variable (6th ed.), New York: HarperCollins College Publishers .
Malet, A, Studies on James Gregorie (1638-1675) (PhD Thesis, Princeton, 1989).
Rudin, Walter (1987), Real and Complex Analysis (third ed.), New York: McGraw-Hill Book Co. 
Stewart, J. (2003), "Fundamental Theorem of Calculus", Calculus: early transcendentals, Belmont, California: Thomson/Brooks/Cole .
Turnbull, H. W., ed. (1939), The James Gregory Tercentenary Memorial Volume, London .
Spivak, Michael (1980), Calculus (2nd ed.), Houstan, Texas: Publish or Perish Inc. .


[edit] External links

James Gregory's Euclidean Proof of the Fundamental Theorem of Calculus at Convergence
Isaac Barrow's proof of the Fundamental Theorem of Calculus








v • d • e

Fundamental mathematical theorems






Arithmetic · Algebra · Calculus · Linear algebra · Calculus of variations · Vector analysis · Homomorphisms · Galois theory






Geometric

Projective · Riemannian · Curves






of Groups

Cyclic · Finitely-generated Abelian









Retrieved from "http://en.wikipedia.org/wiki/Fundamental_theorem_of_calculus"
Categories: Calculus | Mathematical theorems | Articles containing proofs | Fundamental theorems 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


العربية
বাংলা
Български
Català
Dansk
Deutsch
Español
Esperanto
فارسی
Français
文言
한국어
Bahasa Indonesia
Italiano
עברית
ქართული
Lumbaart
Македонски
日本語
‪Norsk (bokmål)‬
Polski
Português
Română
Русский
Slovenščina
Suomi
Svenska
ไทย
Türkçe
Українська
中文









 This page was last modified on 5 April 2009, at 02:30.
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
