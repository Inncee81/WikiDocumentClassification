













Turing test - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Turing_test";
		var wgTitle = "Turing test";
		var wgAction = "view";
		var wgArticleId = "21391751";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 282287946;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Turing test

From Wikipedia, the free encyclopedia

Jump to: navigation, search 
For other uses, see Turing test (disambiguation).




The "standard interpretation" of the Turing Test, in which player C, the interrogator, is tasked with trying to determine which player - A or B - is a computer and which is a human. The interrogator is limited to using the responses to written questions in order to make the determination.


The Turing test is a proposal for a test of a machine's ability to demonstrate intelligence. It proceeds as follows: a human judge engages in a natural language conversation with one human and one machine, each of which tries to appear human. All participants are placed in isolated locations. If the judge cannot reliably tell the machine from the human, the machine is said to have passed the test. In order to test the machine's intelligence rather than its ability to render words into audio, the conversation is limited to a text-only channel such as a computer keyboard and screen.[1]
It was described by Alan Turing in his 1950 paper "Computing Machinery and Intelligence," in which Turing considers the question "can machines think?" Since "thinking" is difficult to define, Turing chose to "replace the question by another which is closely related to it and is expressed in relatively unambiguous words."[2] The question he attempts to answer is whether a machine can pass the Turing test.
In the years since 1950, the test has proven to be both highly influential and widely criticized, and it is an essential concept in the philosophy of artificial intelligence.[3]




Contents


1 History

1.1 Philosophical background
1.2 Alan Turing
1.3 ELIZA and PARRY
1.4 The Chinese room
1.5 Turing Colloquium
1.6 Loebner Prize
1.7 2005 Colloquium on Conversational Systems
1.8 AISB 2008 Symposium on the Turing Test
1.9 Turing100 in 2012


2 Versions of the Turing test

2.1 The Imitation Game
2.2 The standard interpretation
2.3 Imitation Game vs. Standard Turing Test
2.4 Should the interrogator know about the computer?


3 Strengths of the test

3.1 Breadth of subject matter


4 Weaknesses of the test

4.1 Human intelligence vs intelligence in general
4.2 Real intelligence vs simulated intelligence
4.3 Naivete of interrogators and the anthropomorphic fallacy
4.4 Impracticality and irrelevance: the Turing test and AI research


5 Predictions
6 Variations of the Turing test

6.1 Reverse Turing test and CAPTCHA
6.2 Subject matter expert Turing test
6.3 Immortality test
6.4 Minimum Intelligent Signal Test
6.5 Meta Turing test
6.6 Hutter Prize


7 See also
8 Notes
9 References
10 Further reading
11 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] History

[edit] Philosophical background
The question of whether or not it is possible for machines to think has a long history, which is firmly entrenched in the distinction between dualist and materialist views of the mind. From the perspective of dualism, the mind is non-physical (or, at the very least, has non-physical properties[4]) and, therefore, cannot be explained in purely physical terms. The materialist perspective, on the other hand, argues that the mind can be explained physically, and thus leaves open the possibility of minds that are artificially produced.[5]
In 1936, philosopher Alfred Ayer considered the standard philosophical question of other minds: how do we know that other people have the same conscious experiences that we do? In his book Language, Truth and Logic Ayer suggested a protocol to distinguish between a conscious man and an unconscious machine: "The only ground I can have for asserting that an object which appears to be conscious is not really a conscious being, but only a dummy or a machine, is that it fails to satisfy one of the empirical tests by which the presence or absence of consciousness is determined".[6] (This suggestion is very similar to the Turing test, but it is not certain that Ayer's popular philosophical classic was familiar to Turing.)

[edit] Alan Turing
Researchers in Britain had been exploring "machine intelligence" for up to ten years prior to 1956. It was a common topic among the members of the Ratio Club, an informal group of British cybernetics and electronics researchers that included Alan Turing, after whom the test is named.[7]
Turing in particular had been tackling the notion of machine intelligence since at least 1941,[8] and one of the earliest-known mentions of "computer intelligence" was made by him in 1947.[9] In Turing's report, "Intelligent Machinery", he investigated "the question of whether or not it is possible for machinery to show intelligent behaviour"[10] and, as part of that investigation, proposed what may be considered the forerunner to his later tests:

It is not difficult to devise a paper machine which will play a not very bad game of chess.[11] Now get three men as subjects for the experiment. A, B and C. A and C are to be rather poor chess players, B is the operator who works the paper machine. [...] Two rooms are used with some arrangement for communicating moves, and a game is played between C and either A or the paper machine. C may find it quite difficult to tell which he is playing.

Thus, by the time Turing published "Computing Machinery and Intelligence," he had been considering the possibility of artificial intelligence for many years. This, however, was the first published paper[12] by Turing to focus exclusively on the notion.
Turing begins his 1950 paper with the claim "I propose to consider the question 'Can machines think?'"[13] As he highlights, the traditional approach to such a question is to start with definitions, defining both the terms "machine" and "intelligence." Turing, however, chooses not to do so; instead, he replaces the question with a new one, "which is closely related to it and is expressed in relatively unambiguous words".[13] In essence, he proposes to change the question from "Do machines think?" to "Can machines do what we (as thinking entities) can do?"[14] The advantage of the new question, Turing argues, is that it draws "a fairly sharp line between the physical and intellectual capacities of a man."[15]
To demonstrate this approach, Turing proposes a test inspired by a party game known as the "Imitation Game," in which a man and a woman go into separate rooms, and guests try to tell them apart by writing a series of questions and reading the typewritten answers sent back. In this game, both the man and the woman aim to convince the guests that they are the other. Turing proposes recreating the game as follows:

We now ask the question, "What will happen when a machine takes the part of A in this game?" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, "Can machines think?"[16]

Later in the paper, Turing suggests an "equivalent" alternative formulation involving a judge conversing only with a computer and a man.[17] While neither of these formulations precisely match the version of the Turing Test that is more generally known today, he proposed a third in 1952. In this version, which Turing discussed in a BBC radio broadcast, a jury asks questions of a computer, and the role of the computer is to make a significant proportion of the jury believe that it is really a man.[18]
Turing's paper considered nine putative objections, which include all the major arguments against artificial intelligence that have been raised in the years since his paper was first published. (See Computing Machinery and Intelligence.)[19]

[edit] ELIZA and PARRY
Blay Whitby lists four major turning points in the history of the Turing Test — the publication of "Computing Machinery and Intelligence" in 1950, the announcement of Joseph Weizenbaum's ELIZA in 1966, Kenneth Colby's creation of PARRY, which was first described in 1972, and the Turing Colloquium in 1990.[20]
ELIZA works by examining a user's typed comments for keywords. If a keyword is found, a rule is applied which transforms the user's comments, and the resulting sentence is returned. If a keyword is not found, ELIZA responds with either a generic riposte or by repeating one of the earlier comments.[21] In addition, Weizenbaum developed ELIZA to replicate the behaviour of a Rogerian psychotherapist, allowing ELIZA to be "free to assume the pose of knowing almost nothing of the real world."[22] With these techniques, Weizenbaum's program was able to fool some people into believing that they were talking to a real person, with some subjects being "very hard to convince that ELIZA [...] is not human."[22] Thus, ELIZA is claimed by some to be one of the programs (perhaps the first) able to pass the Turing Test,[22][23] although this view is highly contentious (see below).
Colby's PARRY has been described as "ELIZA with attitude":[24] it attempts to model the behaviour of a paranoid schizophrenic, using a similar (if more advanced) approach to that employed by Weizenbaum. In order to validate the work, PARRY was tested in the early 1970s using a variation of the Turing Test. A group of experienced psychiatrists analysed a combination of real patients and computers running PARRY through teletype machines. Another group of 33 psychiatrists were shown transcripts of the conversations. The two groups were then asked to identify which of the "patients" were human and which were computer programs.[25] The psychiatrists were only able to make the correct identification 48 per cent of the time — a figure consistent with random guessing.[26]

[edit] The Chinese room
John Searle's 1980 paper Minds, Brains, and Programs proposed an argument against the Turing Test known as the "Chinese room" thought experiment. Searle argued that software (such as ELIZA) could pass the Turing Test simply by manipulating symbols of which they had no understanding. Without understanding, they could not be described as "thinking" in the same sense people do. Therefore—Searle concludes—the Turing Test cannot prove that a machine can think, contrary to Turing's original proposal.[27]
Arguments such as that proposed by Searle and others working on the philosophy of mind sparked off a more intense debate about the nature of intelligence, the possibility of intelligent machines and the value of the Turing test that continued through the 1980s and 1990s.[28]

[edit] Turing Colloquium
1990 was the fortieth anniversary of the first publication of Turing's "Computing Machinery and Intelligence" paper, and thus saw renewed interest in the test. Two significant events occurred in that year: the first was the Turing Colloquium, which was held at the University of Sussex in April, and brought together academics and researchers from a wide variety of disciplines to discuss the Turing Test in terms of its past, present and future; the second was the formation of the annual Loebner Prize competition.

[edit] Loebner Prize
Main article: Loebner Prize
The Loebner Prize provides an annual platform for practical Turing Tests with the first competition held in November, 1991.[29] It is underwritten by Hugh Loebner; the Cambridge Center for Behavioral Studies in Massachusetts, United States organised the Prizes up to and including the 2003 contest. As Loebner described it, the competition was created to advance the state of AI research, at least in part because "no one had taken steps to implement it."[30]
The first Loebner Prize competition in 1991 led to a renewed discussion of the viability of the Turing Test and the value of pursuing it, in both the popular press[31] and in academia.[32] The first contest was won by a mindless program with no identifiable intelligence that managed to fool naive interrogators into making the wrong identification. This highlighted several of the shortcomings of Turing test (discussed below): the winner won, at least in part, because it was able to "imitate human typing errors";[31] the unsophisticated interrogators were easily fooled;[32] and the test itself is merely a distraction from more fruitful research.[33]
The silver (audio) and gold (audio and visual) prizes have never been won. However, the competition has awarded the bronze medal every year for the computer system that, in the judges' opinions, demonstrates the "most human" conversational behavior among that year's entries. Artificial Linguistic Internet Computer Entity (A.L.I.C.E.) has won the bronze award on three occasions in recent times (2000, 2001, 2004). Learning AI Jabberwacky won in 2005 and 2006. Its creators have proposed a personalized variation: the ability to pass the imitation test while attempting specifically to imitate the human player, with whom the machine will have conversed at length before the test.[34]
The Loebner Prize tests conversational intelligence; winners are typically chatterbot programs, or Artificial Conversational Entities (ACE)s. Early Loebner Prizes ruled restricted conversations: each entry and hidden-human conversed on a single topic, thus the interrogators were restricted to one line of questioning per entity interaction. The restricted conversation rule was lifted for the 1995 Loebner Prize. Interaction duration between judge and entity has varied in Loebner Prizes. In Loebner 2003, at the University of Surrey, each interrogator was allowed five minutes to interact with an entity, machine or hidden-human. Between 2004 and 2007 the interaction time allowed in Loebner Prizes was more than twenty minutes. In 2008 the interrogation duration allowed was five minutes per pair because the organiser (Kevin Warwick), and coordinator (Huma Shah) felt the artificial conversational entities were not technically advanced to converse for longer.[35] Ironically, the 2008 winning entry, Elbot does not mimic a human; its personality is that of a robot yet it deceived three human judges it was the human during human-parallel comparisons.[36]

[edit] 2005 Colloquium on Conversational Systems
In November 2005, the University of Surrey hosted an inaugural one-day meeting of artificial conversational entity developers,[37] attended by winners of practical Turing Tests in the Loebner Prize: Robby Garner, Richard Wallace and Rollo Carpenter. Invited speakers included David Hamill, Hugh Loebner (sponsor of the Loebner Prize) and Huma Shah.

[edit] AISB 2008 Symposium on the Turing Test
In parallel to the 2008 Loebner Prize held at the University of Reading,[38] the Society for the Study of Artificial Intelligence and the Simulation of Behaviour (AISB), hosted a one-day symposium to discuss the Turing Test, organised by John Barnden, Mark Bishop, Huma Shah and Kevin Warwick.[39] The Speakers included Royal Institution's Director Baroness Susan Greenfield, Selmer Bringsjord, Turing's biographer Andrew Hodges and consciousness scientist Owen Holland. No agreement emerged for a canonical Turing Test, however Bringsjord expressed that a sizeable prize would result in the Turing Test being passed sooner.

[edit] Turing100 in 2012
A committee set up to organise events celebrating the 100th anniversary of Turing's birth in 2012, with a goal to take Turing's idea for a thinking machine, picturised in Hollywood movies such as Blade Runner, to a wider audience including children. Provisional members include Kevin Warwick, Chair, Huma Shah, coordinator, Ian Bland, Chris Chapman, Marc Allen, Rory Dunlop, Loebner winners Robby Garner and Fred Roberts. It is supported by Women in Technology and Daden Ltd.

[edit] Versions of the Turing test




The Imitation Game, as described by Alan Turing in "Computing Machinery and Intelligence." Player C, through a series of written questions, attempts to determine which of the other two players is a man, and which of the two is the woman. Player A, the man, tries to trick player C into making the wrong decision, while player B tries to help player C.


There are at least three primary versions of the Turing test, two of which are offered in "Computing Machinery and Intelligence" and one which Saul Traiger describes as the "Standard Interpretation."[40] While there is some debate as to whether or not the "Standard Interpretation" is that described by Turing or, instead, based on a misreading of his paper, these three versions are not regarded as equivalent,[40] and their strengths and weaknesses are distinct.

[edit] The Imitation Game
Turing, as we have seen, described a simple party game involving three players. Player A is a man, player B a woman and player C (who plays the role of the interrogator) of either gender. In the Imitation Game, player C is unable to see either player A or player B, and can only communicate with them through written notes. By asking questions of player A and player B, player C tries to determine which of the two is the man and which is the woman. Player A's role is to trick the interrogator into making the wrong decision, while player B attempts to assist the interrogator in making the right one.[41]
In what SG Sterret refers to as the "Original Imitation Game Test,"[42] Turing proposes that the role of player A be filled by a computer. The computer's task is thus to pretend to be a woman and attempt to trick the interrogator into making an incorrect evaluation. The success of the computer is determined by comparing the outcome of the game when player A is a computer against the outcome when player A is a man. If, as Turing puts it, "the interrogator decide[s] wrongly as often when the game is played [with the computer] as he does when the game is played between a man and a woman"[15], it may be argued that the computer is intelligent.




The Original Imitation Game Test, in which the player A is replaced with a computer. The computer is now charged with the role of the woman, while player B continues to attempt to assist the interrogator.


The second version appears later in Turing's 1950 paper. As with the Original Imitation Game Test, the role of player A is performed by a computer, the difference being that the role of player B is now to be performed by a man rather than a woman.


"Let us fix our attention on one particular digital computer C. Is it true that by modifying this computer to have an adequate storage, suitably increasing its speed of action, and providing it with an appropriate programme, C can be made to play satisfactorily the part of A in the imitation game, the part of B being taken by a man?"

—Turing 1950, p. 442

In this version, both player A (the computer) and player B are trying to trick the interrogator into making an incorrect decision.[43]

[edit] The standard interpretation
Common understanding has it that the purpose of the Turing Test is not specifically to determine whether a computer is able to fool an interrogator into believing that it is a woman, but rather whether or not a computer could imitate a human.[43] While there is some dispute as to whether or not this interpretation was intended by Turing — Sterrett believes that it was[42] and thus conflates the second version with this one, while others, such as Traiger, do not[40] — this has nevertheless led to what can be viewed as the "standard interpretation.". In this version, player A is a computer and player B a person of either gender. The role of the interrogator is not to determine which is male and which is female, but which is a computer and which is a human.[44]

[edit] Imitation Game vs. Standard Turing Test
There has arisen some controversy over which of the alternative formulations of the test Turing intended.[42] Sterrett argues that two distinct tests can be extracted from his 1950 paper and that, pace Turing's remark, they are not equivalent. The test that employs the party game and compares frequencies of success is referred to as the "Original Imitation Game Test," whereas the test consisting of a human judge conversing with a human and a machine is referred to as the "Standard Turing Test," noting that Sterrett equates this with the "standard interpretation" rather than the second version of the imitation game. Sterrett agrees that the Standard Turing Test (STT) has the problems that its critics cite but feels that, in contrast, the Original Imitation Game Test (OIG Test) so defined is immune to many of them, due to a crucial difference: unlike the STT, it does not make similarity to human performance the criterion, even though it employs human performance in setting a criterion for machine intelligence. A man can fail the OIG Test, but it is argued that it is a virtue of a test of intelligence that failure indicates a lack of resourcefulness: the OIG Test requires the resourcefulness associated with intelligence and not merely "simulation of human conversational behaviour." The general structure of the OIG Test could even be used with non-verbal versions of imitation games.[45]
Still other writers[46] have interpreted Turing as proposing that the imitation game itself is the test, without specifying how to take into account Turing's statement that the test that he proposed using the party version of the imitation game is based upon a criterion of comparative frequency of success in that imitation game, rather than a capacity to succeed at one round of the game.

[edit] Should the interrogator know about the computer?
Turing never makes clear whether or not the interrogator in his tests is aware that one of the participants is a computer. To return to the Original Imitation Game, he states only that player A is to be replaced with a machine, not that player C is to be made aware of this replacement.[15] When Colby, FD Hilf, S Weber and AD Kramer tested PARRY, they did so by assuming that the interrogators did not need to know that one or more of those being interviewed was a computer during the interrogation.[47] As Ayse Saygin and others highlight, however, this makes a big difference to the implementation and outcome of the test.[48]. However, Shah & Warwick, who have organised practical Turing tests, disagree; knowing/not knowing may make a difference in some judges' verdict.

[edit] Strengths of the test

[edit] Breadth of subject matter
The power of the Turing test derives from the fact that it is possible to talk about anything. Turing wrote that "the question and answer method seems to be suitable for introducing almost any one of the fields of human endeavor that we wish to include."[49] John Haugeland adds that "understanding the words is not enough; you have to understand the topic as well."[50]
In order to pass a well-designed Turing test, the machine must use natural language, reason, have knowledge and learn. The test can be extended to include video input, as well as a "hatch" through which objects can be passed: this would force the machine to demonstrate the skill of vision and robotics as well. Together, these represent almost all of the major problems of artificial intelligence.[51]

[edit] Weaknesses of the test
The Turing test is based on the assumption that human beings can judge a machine's intelligence by comparing its behaviour with human behaviour. Every element of this assumption has been questioned: the human's judgement, the value of comparing only behaviour and the value of comparing against a human. Because of these and other considerations, some AI researchers have questioned the usefulness of the test.

[edit] Human intelligence vs intelligence in general







It does not directly test if the computer behaves intelligently, it only tests whether or not the computer behaves like a human being. Since human behaviour and intelligent behaviour are not exactly the same thing, the test can fail to accurately measure intelligence in two ways:

Some human behaviour is unintelligent
The Turing test requires that the machine be able to execute all human behaviours, regardless of whether or not they are intelligent. It even tests for behaviours that we may not consider intelligent at all, such as the susceptibility to insults, the temptation to lie or, simply, a high frequency of typing mistakes. If a machine cannot imitate human behaviour in detail, bad typing and all, it fails the test, regardless of how intelligent it may be.


This objection was raised by The Economist, in an article entitled "Artificial Stupidity" published shortly after the first Loebner prize competition in 1992. The article noted that the first Loebner winner's victory was due, at least in part, to its ability to "imitate human typing errors".[31] Turing himself had suggested that programs add errors into their output, so as to be better "players" of the game.[52]


Some intelligent behaviour is inhuman
The Turing test does not test for highly intelligent behaviours, such as the ability to solve difficult problems or come up with original insights. In fact, it specifically requires deception on the part of the machine: if the machine is more intelligent than a human being it must deliberately avoid appearing too intelligent. If it were to solve a computational problem that is impossible for any human to solve, then the interrogator would know the program is not human, and the machine would fail the test.


[edit] Real intelligence vs simulated intelligence
See also: synthetic intelligence
It only tests how the subject acts—the external behaviour of the machine. In this regard, it assumes a behaviourist or functionalist definition of intelligence. The example of ELIZA suggested that a machine passing the test may be able to simulate human conversational behaviour by following a simple (but large) list of mechanical rules, without thinking or having a mind at all.
John Searle argued that external behaviour can not be used to determine if a machine is "actually" thinking or merely "simulating thinking".[53] His chinese room argument is intended to show that, even if the Turing test is a good operational definition of intelligence, it may not indicate that the machine has a mind, consciousness, the ability to "understand" or have actual thoughts that "mean" anything (what philosophers call intentionality).
Turing responded to this line of criticism in his original paper,[54] writing that:


I do not wish to give the impression that I think there is no mystery about consciousness. There is, for instance, something of a paradox connected with any attempt to localise it. But I do not think these mysteries necessarily need to be solved before we can answer the question with which we are concerned in this paper.

— Alan Turing, (Turing 1950)


[edit] Naivete of interrogators and the anthropomorphic fallacy
The Turing test assumes that the interrogator is sophisticated enough to determine the difference between the behaviour of a machine and the behaviour of a human being. However, critics argue that this is not a skill that most people have. The precise skills and knowledge required by the interrogator are not specified by Turing in his description of the test.
Chatterbot programs such as ELIZA have repeatedly fooled unsuspecting people into believing that they are communicating with human beings. In these cases, the "interrogator" is not even aware of the possibility that they are interacting with a computer. To successfully appear human, there is no need for the machine to have any intelligence whatsoever and only a superficial resemblance to human behaviour is required. Most would agree that a "true" Turing test has not been passed in "uninformed" situations like these.
Early Loebner prize competitions used "unsophisticated" interrogators who were easily fooled by the machines.[32] Since 2004, the Loebner Prize organizers have deployed philosophers, computer scientists and journalists among the interrogators.
Michael Shermer points out that human beings consistently choose to consider non-human objects as human whenever they are allowed the chance, a mistake called the anthropomorphic fallacy: they talk to their cars, ascribe desire and intentions to natural forces (e.g. "nature abhors a vacuum"), and worship the sun as a human-like being with intelligence. If the Turing test is applied to religious objects, Shermer argues, then inanimate statues, rocks and places have consistently passed the test throughout history.[55] This human tendency towards anthropomorphism effectively lowers the bar for the Turing test, unless interrogators are specifically trained to avoid it.

[edit] Impracticality and irrelevance: the Turing test and AI research
Mainstream AI researchers argue that trying to pass the Turing Test is merely a distraction from more fruitful research.[33] Indeed, the Turing test is not an active focus of much mainstream academic or commercial effort—as Stuart Russell and Peter Norvig write: "AI researchers have devoted little attention to passing the Turing test."[56] There are several reasons.
First, there are easier ways to test their programs. Most current research in AI-related fields is aimed at modest and specific goals, such as automated scheduling, object recognition or logistics. In order to test the intelligence of the programs that solve these problems, AI researchers simply give them the task directly, rather than going through the roundabout method of posing the question in a chat room populated with computers and people.
Second, creating life-like simulations of human beings is a difficult problem on its own that does not need to be solved to achieve the basic goals of AI research. Believable human characters may be interesting in a work of art, a game or a sophisticated user interface, but they are not part of the science of creating intelligent machines—that is, machines that solve problems using intelligence. Russell and Norvig suggest an analogy with the history of flight: planes are tested by how well they fly, not by comparing them to birds. "Aeronautical engineering texts," they write, "do not define the goal of their field as 'making machines that fly so exactly like pigeons that they can fool other pigeons.'"[56]
Turing, for his part, never intended his test to be used as a practical, day-to-day measure of the intelligence of AI programs; he wanted to provide a clear and understandable example to aid in the discussion of the philosophy of artificial intelligence.[57] As such, it is not surprising that the Turing test has had so little influence on AI research—the philosophy of AI, writes John McCarthy, "is unlikely to have any more effect on the practice of AI research than philosophy of science generally has on the practice of science."[58]

[edit] Predictions
Turing predicted that machines would eventually be able to pass the test; in fact, he estimated that by the year 2000, machines with 109 bits (about 119.2 MiB or approximately 120 megabytes) of memory would be able to fool thirty per cent of human judges in a five-minute test. He also predicted that people would then no longer consider the phrase "thinking machine" contradictory. He further predicted that machine learning would be an important part of building powerful machines, a claim considered plausible by contemporary researchers in artificial intelligence.
By extrapolating an exponential growth of technology over several decades, futurist Raymond Kurzweil predicted that Turing test-capable computers would be manufactured in the near future. In 1990, he set the year around 2020.[59] By 2005, he had revised his estimate to 2029.[60]
The Long Bet Project is of $10,000 between Mitch Kapor (pessimist) and Kurzweil (optimist) about whether a computer will pass a Turing Test by the year 2029. The bet specifies the conditions in some detail.[61]

[edit] Variations of the Turing test
Numerous other versions of the Turing test, including those expounded above, have been mooted through the years.

[edit] Reverse Turing test and CAPTCHA
Main articles: reverse Turing test and CAPTCHA
A modification of the Turing test wherein the objective of one or more of the roles have been reversed between machines and humans is termed a reverse Turing test. An example is implied in the work of psychoanalyst Wilfred Bion,[62] who was particularly fascinated by the "storm" that resulted from the encounter of one mind by another. Carrying this idea forward, R. D. Hinshelwood[63] described the mind as a "mind recognizing apparatus", noting that this might be some sort of "supplement" to the Turing test. The challenge would be for the computer to be able to determine if it were interacting with a human or another computer. This is an extension of the original question that Turing attempted answer but would, perhaps, offer a high enough standard to define a machine that could "think" in a way that we typically define as characteristically human.
CAPTCHA is a form of reverse Turing test. Before being allowed to perform some action on a website, the user is presented with alphanumerical characters in a distorted graphic image and asked to type them out. This is intended to prevent automated systems from abusing the site. The rationale is that software sufficiently sophisticated to read and reproduce the distorted image accurately does not exist (or is not available to the average user), so any system able to do so is likely to be a human. The implication would appear to be (although is not necessarily) that artificial intelligence has not as yet been achieved.

[edit] Subject matter expert Turing test
Main article: Subject matter expert Turing test
Another variation is described as the subject matter expert Turing test, where a machine's response cannot be distinguished from an expert in a given field. This is also known as a "Feigenbaum test" and was proposed by Edward Feigenbaum in a 2003 paper.[64]

[edit] Immortality test
Main article: Immortality test
The Immortality-test variation of the Turing test would determine if a person's essential character is reproduced with enough fidelity to make it impossible to distinguish a reproduction of a person from the original person.

[edit] Minimum Intelligent Signal Test
Main article: Minimum Intelligent Signal Test
The Minimum Intelligent Signal Test, proposed by Chris McKinstry, is another variation of Turing's test, where only binary responses are permitted. It is typically used to gather statistical data against which the performance of artificial intelligence programs may be measured.

[edit] Meta Turing test
Yet another variation is the Meta Turing test, in which the subject being tested (say, a computer) is classified as intelligent if it itself has created something that the subject itself wants to test for intelligence.

[edit] Hutter Prize
The organizers of the Hutter Prize believe that compressing natural language text is a hard AI problem, equivalent to passing the Turing test.
The data compression test has some advantages over most versions and variations of a Turing test, including:

It gives a single number that can be directly used to compare which of two machines is "more intelligent".
It doesn't require the computer to lie to the judge -- teaching computers to lie is widely regarded as a bad idea.[65]

The main disadvantages of using data compression as a test are:

It is not possible to test humans this way.
It is unknown what particular "score" on this test -- if any -- is equivalent to passing a human-level Turing test.


[edit] See also

Artificial intelligence in fiction
Computer game bot Turing Test
Graphics Turing Test
HAL 9000 (Kubrick's AI)
Mark V Shaney (USENET bot)
Simulated reality
Technological singularity
Uncanny valley
Voight-Kampff machine


[edit] Notes


^ Turing originally suggested a teletype machine, one of the few text-only communication systems available in 1950.
^ Turing 1950
^ Russell & Norvig 2003, pp. 2-3 and 948
^ For an example of property dualism, see Qualia.
^ Noting that materialism does not necessitate the possibility of artificial minds (for example, Roger Penrose), any more than dualism necessarily precludes the possibility. (See, for example, Property dualism.)
^ Language, Truth and Logic (p. 140), Penguin 2001.
^ McCorduck 2004, p. 95
^ Copeland 2003, p. 1
^ Copeland 2003, p. 2
^ Turing 1948, p. 412
^ In 1948, working with his former undergraduate colleague, DG Champernowne, Turing began writing a chess program for a computer that did not yet exist and, in 1952, lacking a computer powerful enough to execute the program, played a game in which he simulated it, taking about half an hour over each move. The game was recorded, and the program lost to Turing's colleague Alick Glennie, although it is said that it won a game against Champernowne's wife.
^ "Intelligent Machinery" was not published by Turing, and did not see publication until 1968 in Evans, C. R. & Robertson, A. D. J. (1968) Cybernetics: Key Papers, University Park Press.
^ a b Turing 1950, p. 433
^ Harnad, p. 1
^ a b c Turing 1950, p. 434
^ Harvnb|Turing|1950|p=434
^ Turing 1950, p. 446
^ Turing 1952, pp. 524-525. Turing does not seem to distinguish between "man" as a gender and "man" as a human. In the former case, this formulation would be closer to the Imitation Game, while in the latter it would be closer to current depictions of the test.
^ Turing 1950 and see Russell & Norvig 2003, p. 948, where they comment, "Turing examined a wide variety of possible objections to the possibility of intelligent machines, including virtually all of those that have been raised in the half century since his paper appeared."
^ Whitby 1996, p. 53
^ Weizenbaum 1966, p. 37
^ a b c Weizenbaum 1966, p. 42
^ Thomas 1995, p. 112
^ Bowden 2006, p. 370
^ Colby et al. 1972, p. 42
^ Saygin, Cicekli & Akman 2000, p. 501
^ Searle 1980
^ Saygin, Cicekli & Akman 2000, p. 479
^ Sundman 2003
^ Loebner 1994
^ a b c "Artificial Stupidity" 1992
^ a b c Shapiro 1992 and Shieber 1994, amongst others.
^ a b Shieber 1994
^ See [1].[dead link]
^ Shah, Huma (15 January 2009). "Winner of 2008 Loebner Prize for Artificial Intelligence". Conversation, Deception and Intelligence. http://humashah.blogspot.com/. Retrieved on 29 March 2009. 
^ Transcripts can be found at "Loebner Prize". http://www.loebner.net/Prizef/loebner-prize.html. Retrieved on 29 March 2009. 
^ "ALICE Anniversary and Colloquium on Conversation". A.L.I.C.E. Artificial Intelligence Foundation. http://www.alicebot.org/bbbbbbb.html. Retrieved on 29 March 2009. 
^ "Loebner Prize 2008". University of Reading. http://www.reading.ac.uk/cirg/loebner/cirg-loebner-main.asp. Retrieved on 29 March 2009. 
^ "AISB 2008 Symposium on the Turing Test". Society for the Study of Artificial Intelligence and the Simulation of Behaviour. http://www.aisb.org.uk/events/turingevent.shtml. Retrieved on 29 March 2009. 
^ a b c Traiger 2000
^ Turing 1950, p. 433-434
^ a b c Moor 2003
^ a b Saygin et al 2000, p. 252
^ Traiger 2000, p. 99
^ Sterrett 2000
^ Genova 1994, Hayes & Ford 1995, Heil 1998, Dreyfus 1979
^ Colby et al 1972
^ Saygin et al 2000, p. 60
^ Turing 1950 under "Critique of the New Problem"
^ Haugeland 1985, p. 8
^ "These six disciplines," write Stuart J. Russell and Peter Norvig, "represent most of AI". Russell & Norvig 2003, p. 3
^ Turing 1950, p. 448
^ Searle 1980
^ Russell & Norvig (2003, pp. 958-960) identify Searle's argument with the one Turing answers.
^ Shermer YEAR? CITATION IN PROGRESS
^ a b Russell & Norvig 2003, p. 3
^ Turing 1950, under the heading "The Imitation Game", where he writes, "Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words."
^ John McCarthy The philosophy of artificial intelligence
^ Kurzweil 1990
^ Kurzweil 2005
^ Long Bets - By 2029 no computer - or "machine intelligence" - will have passed the Turing Test
^ Bion 1979
^ Hinshelwood 2001
^ McCorduck 2003, pp. 503-505, Feigenbaum 2003. The subject matter expert test is also mentioned in Kurzweil (2005)
^ "What if a Computer Lies?" Lakshminarayanan Subramanian



[edit] References


"Artificial Stupidity", The Economist 324 (7770): 14, 1992-09-01 
Bion, W.S. (1979), "Making the best of a bad job", Clinical Seminars and Four Papers, Abingdon: Fleetwood Press. 
Bowden, Margaret A. (2006), Mind As Machine: A History of Cognitive Science, Oxford University Press, ISBN 9780199241446 
Colby, K. M.; Hilf, F. D.; Weber, S.; Kraemer (1972), "Turing-like indistinguishability tests for the validation of a computer simulation of paranoid processes", Artificial Intelligence 3: 199–221, doi:10.1016/0004-3702(72)90049-5 
Copeland, Jack (2003), Moor, James, ed., The Turing Test, Springer, ISBN 1-40-201205-5 
Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0-465-02997-3 
Dreyfus, Hubert (1979), What Computers Still Can't Do, New York: MIT Press, ISBN ISBN 0-06-090613-8 
Feigenbaum, Edward A. (2003), "Some challenges and grand challenges for computational intelligence", Journal of the ACM 50 (1): 32–40, doi:10.1145/602382.602400 
Genova, J. (1994), "Turing's Sexual Guessing Game", Social Epistemology 8 (4): 314–326, doi:10.1080/02691729408578758 
Harnad, Stevan (2004), "The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence", in Epstein, Robert; Peters, Grace, The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer, Klewer, http://cogprints.org/3322/ 
Haugeland, John (1985), Artificial Intelligence: The Very Idea, MIT Press .
Hayes, Patrick; Ford, Kenneth (1995), "Turing Test Considered Harmful", Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence (IJCAI95-1), Montreal, Quebec, Canada.: 972–997 
Heil, John (1998), Philosophy of Mind: A Contemporary Introduction, London and New York: Routledge, ISBN 0-415-13060-3 
Hinshelwood, R.D. (2001), Group Mentality and Having a Mind: Reflections on Bion's work on groups and on psychosis 
Kurzweil, Ray (1990), The Age of Intelligent Machines, Cambridge, Mass.: MIT Press, ISBN 0-262-61079-5 
Kurzweil, Ray (2005), The Singularity is Near, Penguin Books, ISBN 0-670-03384-7 
Loebner, Hugh Gene (1994), "In response", Communications of the ACM 37 (6): 79–82, doi:10.1145/175208.175218, http://loebner.net/Prizef/In-response.html, retrieved on 2008-03-22 
McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 1-56881-205-1, http://www.pamelamc.com/html/machines_who_think.html 
Moor, James, ed. (2003), The Turing Test: The Elusive Standard of Artificial Intelligence, Dordrecht: Kluwer Academic Publishers, ISBN 1-4020-1205-5 
Penrose, Roger (1989), The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics, Oxford University Press, ISBN 0-14-014534-6 
Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, NJ: Prentice Hall, ISBN 0-13-790395-2 
Saygin, Ayse Pinar; Cicekli, Ilyas; Akman, Varol (2000), Turing Test: 50 Years Later  in Moor, James, ed. (2003), The Turing Test: The Elusive Standard of Artificial Intelligence, Springer, ISBN 1-40-201205-5 
Searle, John (1980), "Minds, Brains and Programs", Behavioral and Brain Sciences 3 (3): 417–457, http://members.aol.com/NeoNoetics/MindsBrainsPrograms.html . Page numbers above refer to a standard pdf print of the article. See also Searle's original draft.
Shapiro, Stuart C. (1992), "The Turing Test and the economist", ACM SIGART Bulletin 3 (4): 10–11, doi:10.1145/141420.141423 
Shieber, Stuart M. (1994), "Lessons from a Restricted Turing Test", Communications of the ACM 37 (6): 70–78, doi:10.1145/175208.175217, http://www.eecs.harvard.edu/shieber/Biblio/Papers/loebner-rev-html/loebner-rev-html.html, retrieved on 2008-03-25 
Sterrett, S. G. (2000), "Turing's Two Test of Intelligence", Minds and Machines 10 (4): 541, doi:10.1023/A:1011242120015  (reprinted in The Turing Test: The Elusive Standard of Artificial Intelligence edited by James H. Moor, Kluwer Academic 2003) ISBN 1-4020-1205-5
Sundman, John (February 26, 2003), "Artificial stupidity", Salon.com, http://dir.salon.com/story/tech/feature/2003/02/26/loebner_part_one/index.html, retrieved on 2008-03-22 
Thomas, Peter J. (1995), The Social and Interactional Dimensions of Human-Computer Interfaces, Cambridge University Press, ISBN 052145302X 
Traiger, Saul (2000), "Making the Right Identification in the Turing Test", Minds and Machines 10 (4): 561, doi:10.1023/A:1011254505902  (reprinted in The Turing Test: The Elusive Standard of Artificial Intelligence edited by James H. Moor, Kluwer Academic 2003) ISBN 1-4020-1205-5
Turing, Alan (1948), "Machine Intelligence", in Copeland, B. Jack, The Essential Turing: The ideas that gave birth to the computer age, Oxford: Oxford University Press, ISBN 0-19-825080-0 
Turing, Alan (October 1950), "Computing Machinery and Intelligence", Mind LIX (236): 433–460, doi:10.1093/mind/LIX.236.433, ISSN 0026-4423, http://loebner.net/Prizef/TuringArticle.html, retrieved on 2008-08-18 
Turing, Alan (1952), "Can Automatic Calculating Machines be Said to Think?", in Copeland, B. Jack, The Essential Turing: The ideas that gave birth to the computer age, Oxford: Oxford University Press, ISBN 0-19-825080-0 
Zylberberg, A.; Calot, E. (2007), "Optimizing Lies in State Oriented Domains based on Genetic Algorithms", Proceedings VI Ibero-American Symposium on Software Engineering: 11–18, ISBN 978-9972-2885-1-7 
Weizenbaum, Joseph (January 1966), "ELIZA - A Computer Program For the Study of Natural Language Communication Between Man And Machine", Communications of the ACM 9 (1): 36–45, doi:10.1145/365153.365168 
Whitby, Blay (1996), "The Turing Test: AI's Biggest Blind Alley?", in Millican, Peter & Clark, Andy, Machines and Thought: The Legacy of Alan Turing, 1, Oxford University Press, pp. 53–62, ISBN 0-19-823876-2 
Adams, Scott (2008), Dilbert, http://www.dilbert.com/comics/dilbert/archive/images/dilbert2008033349280.jpg 



[edit] Further reading


B. Jack Copeland, ed., The Essential Turing: The ideas that gave birth to the computer age (2004). ISBN 0-19-825080-0
Larry Gonick, The Cartoon Guide to the Computer (1983, originally The Cartoon Guide to Computer Science). ISBN 0-06-273097-5.
S. G. Sterrett "Nested Algorithms and the 'Original Imitation Game Test'," Minds and Machines (2002). ISSN 0924-6495
A.P. Saygin, I. Cicekli, and V Akman (2000), 'Turing Test: 50 Years Later', Minds and Machines 10(4): 463-518. (reprinted in The Turing Test: The Elusive Standard of Artificial Intelligence edited by James H. Moor, Kluwer Academic 2003) ISBN 1-4020-1205-5. (Thorough review. Online version at [2] )
Saygin, A.P. & Cicekli I (2002): Pragmatics in human-computer conversations (Abstract and links to pdf, if permitted), Journal of Pragmatics, Volume 34, Issue 3, March 2002, Pages 227-258.
Shah, H. (2006): "Chatterbox Challenge 2005: Geography of a Modern Eliza" Proceedings of 3rd International Workshop on Natural Language Understanding and Cognitive Science – NLUCS 2006 in conjunction with ICEIS 2006 Cyprus, Paphos, May 2006 ISBN 972-8865-50-3 pp 133–138
Shah, H. (2005): A.L.I.C.E.: an ACE in Digitaland TripleC, Vol 4, No 2
Shah, H. & Henry, O. (2005): Confederate Effect in Human-Machine Textual Interaction Proceedings of 5th WSEAS Int. Conf. on Information Science, Communications and Applications (WSEAS ISCA), May 11– 14, 2005, Cancun, Mexico, ISBN 960-8457-22-X, pp 109–114



[edit] External links

Twelve reasons to toss the Turing Test
The Turing Test - an Opera by Julian Wagstaff
Turing Test at the Open Directory Project
The Turing Test- How accurate could the turing test really be?
Stanford Encyclopedia of Philosophy entry on the Turing test, by G. Oppy and D. Dowe.
The Turing Test Page lists recent articles, links, and other info on the test.
Turing Test: 50 Years Later reviews a half-century of work on the Turing Test, from the vantage point of 2000.
Bet between Kapor and Kurzweil, including detailed justifications of their respective positions.
Why The Turing Test is AI's Biggest Blind Alley by Blay Witby
A humorous look at proving the non-intelligence of a Twinkie
TuringHub.com Take the Turing Test, live, online
Jabberwacky.com An AI chatterbot that learns from and imitates humans
New York Times essays on machine intelligence part 1 and part 2
Today’s Bewildering Conversation with a Three-Year-Old Jeopardy winner Ken Jennings blogs about a humorous Turing-challenged conversation with his toddler son.
Machines Who Think": Scientific American Frontiers video on "the first ever [restricted] Turing test."
Virtual Humans Forum.
Wiki News: "Talk:Computer professionals celebrate 10th birthday of A.L.I.C.E."
xkcd joke about Turing tests




Retrieved from "http://en.wikipedia.org/wiki/Turing_test"
Categories: Turing tests | Philosophy of artificial intelligence | Alan Turing | Human-computer interaction | History of artificial intelligenceHidden categories: All articles with dead external links | Articles with dead external links since March 2009 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Български
Català
Česky
Dansk
Deutsch
Eesti
Español
Esperanto
فارسی
Français
Galego
한국어
Hrvatski
Íslenska
Italiano
עברית
Latviešu
Magyar
Nederlands
日本語
‪Norsk (bokmål)‬
Polski
Português
Română
Русский
Simple English
Slovenčina
Српски / Srpski
Suomi
Svenska
ไทย
Türkçe
Українська
中文









 This page was last modified on 7 April 2009, at 06:43.
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
