













Tit for tat - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Tit_for_tat";
		var wgTitle = "Tit for tat";
		var wgAction = "view";
		var wgArticleId = "267800";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 278120882;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Tit for tat

From Wikipedia, the free encyclopedia

Jump to: navigation, search 





This article needs additional citations for verification. Please help improve this article by adding reliable references (ideally, using inline citations). Unsourced material may be challenged and removed. (December 2007)






A handshake when meeting someone is an example of initial cooperation


For the Laurel and Hardy film, see Tit for Tat (1935 film).
Tit for tat is a highly effective strategy in game theory for the iterated prisoner's dilemma. It was first introduced by Anatol Rapoport in Robert Axelrod's two tournaments, held around 1980. Based on the English saying meaning "equivalent retaliation" ("tit for tat"), an agent using this strategy will initially cooperate, then respond in kind to an opponent's previous action. If the opponent previously was cooperative, the agent is cooperative. If not, the agent is not. This is similar to reciprocal altruism in biology.




Contents


1 Overview
2 Example of play
3 Implications
4 Problems
5 Tit for two tats
6 Real world use

6.1 Peer-to-peer file sharing
6.2 Explaining Reciprocal Altruism in Animal Communities
6.3 War


7 Popular culture
8 See also
9 References
10 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Overview
This strategy is dependent on four conditions that has allowed it to become the most prevalent strategy for the prisoner's dilemma:

Unless provoked, the agent will always cooperate
If provoked, the agent will retaliate
The agent is quick to forgive
The agent must have a good chance of competing against the opponent more than once.

In the last condition, the definition of "good chance" depends on the payoff matrix of the prisoner's dilemma. The important thing is that the competition continues long enough for repeated punishment and forgiveness to generate a long-term payoff higher than the possible loss from cooperating initially.
A fifth condition applies to make the competition meaningful: if an agent knows that the next play will be the last, it should naturally defect for a higher score. Similarly if it knows that the next two plays will be the last, it should defect twice, and so on. Therefore the number of competitions must not be known in advance to the agents.
Against a variety of alternative strategies, tit for tat was the most effective, winning in several annual automated tournaments against (generally far more complex) strategies created by teams of computer scientists, economists, and psychologists. Game theorists informally believed the strategy to be optimal (although no proof was presented).
It is important to know that tit for tat still is the most effective strategy if the average performance of each competing team is compared. The team which recently won over a pure tit for tat team only outperformed it with some of their algorithms because they submitted multiple algorithms which would recognize each other and assume a master and slave relationship (one algorithm would "sacrifice" itself and obtain a very poor result in order for the other algorithm to be able to outperform Tit for Tat on an individual basis, but not as a pair or group). Still, this "group" victory illustrates an important limitation of the Prisoner's Dilemma in representing social reality, namely, that it does not include any natural equivalent for friendship or alliances. The advantage of "tit for tat" thus pertains only to a Hobbesian world of rational solutions, not to a world in which humans are inherently social.[citation needed]

[edit] Example of play



Cooperate
Defect


Cooperate
3, 3
0, 5


Defect
5, 0
1, 1


Prisoner's dilemma example


Assume there are 4 agents: 2 are Tit for Tat players ("variables") and 2 are "Defectors", simply trying to maximize their own winnings by always giving evidence against the other. Assume that each player faces the other 3 in a match lasting 6 games. If one player gives evidence against a player who does not, the former gains 5 points and the latter nets 0. If both refrain from giving evidence, both gain 3 points. If both give evidence against each other, both gain 1 point.
When a variable faces off against a defector, the former refrains from giving evidence in the first game while the defector does the opposite, gaining the control 5 points. In the remaining 5 games, both players give evidence against each other, netting 1 point each game. The final score is: Defector - 10 | Variable - 5.
When the variables face off against each other, each refrains from giving evidence in all 6 games. 6 * 3 = 18 points, the final score being Variable(1) - 18 | Variable(2) - 18.
When the defectors face off, each gives evidence against the other in all 6 games. 6 * 1 = 6 points, the final score being Defector(1) - 6 | Defector(2) - 6.
The final score for each variable is 5 (game against defector(1)) + 5 (game against defector(2)) + 18 (game against variable) = 28 points. The final score for each defector is 10 (against variable(1)) + 10 (against variable(2)) + 6 (against defector) = 26 points.
Despite the fact that the variables never won a match and the defectors never lost a match, the variables still came out ahead, because the final score is not determined by the winner of matches, but the scorer of points. Simply put, the variables gained more points tying with each other than they lost to the defectors. The more variables that there are in the game, the more advantage it is to be a variable.
(This example was taken from Piers Anthony's novel, Golem in the Gears.)

[edit] Implications
The success of the strategy, which is largely cooperative, took many by surprise. In successive competitions various teams produced complex strategies which attempted to "cheat" in a variety of cunning ways, but Tit for Tat eventually prevailed in every competition.
Some theorists believe this result may give insight into how groups of animals (and particularly human societies) have come to live in largely (or entirely) cooperative societies, rather than the individualistic "red in tooth and claw" way that might be expected from individual engaged in a Hobbesian state of nature. This, and particularly its application to human society and politics, is the subject of Robert Axelrod's book The Evolution of Cooperation.

[edit] Problems
While Axelrod has empirically shown that the strategy is optimal in some cases, two agents playing tit for tat remain vulnerable. A one-time, single-bit error in either player's interpretation of events can lead to an unending "death spiral". In this symmetric situation, each side perceives itself as preferring to cooperate, if only the other side would. But each is forced by the strategy into repeatedly punishing an opponent who continues to attack despite being punished in every game cycle. Both sides come to think of themselves as innocent and acting in self-defense, and their opponent as either evil or too stupid to learn to cooperate.
This situation frequently arises in real world conflicts, ranging from schoolboy fights to civil and regional wars. Tit for two tats could be used to avoid this problem.[citation needed]
"Tit for Tat with forgiveness" is sometimes superior. When the opponent defects, the player will occasionally cooperate on the next move anyway. This allows for recovery from getting trapped in a cycle of defections. The exact probability that a player will respond with cooperation depends on the line-up of opponents.
The reason for these issues is that tit for tat is not a subgame perfect equilibrium.[1] If one agent defects and the opponent cooperates, then both agents will end up alternating cooperate and defect, yielding a lower payoff than if both agents were to continually cooperate. While this subgame is not directly reachable by two agents playing tit for tat strategies, a strategy must be a Nash equilibrium in all subgames to be subgame perfect. Further, this subgame may be reached if any noise is allowed in the agents' signaling. A subgame perfect variant of tit for tat known as "contrite tit for tat" may be created by employing a basic reputation mechanism.[2]

[edit] Tit for two tats
Tit for Two Tats is similar to Tit for Tat in that it is nice, retaliating, forgiving and non-envious, the only difference between the two being how nice the strategy is.
In a tit for tat strategy once an opponent defects, the tit for tat player immediately responds by defecting on the next move. This has the unfortunate consequence of causing two retaliatory strategies to continuously defect against one another resulting in a poor outcome for both players. A tit for two tats player will let the first defection go unchallenged as a means to avoid the "death spiral" of the previous example. If the opponent defects twice in a row, the tit for two tats player will respond by defecting.
This strategy was put forward by Robert Axelrod during his second round of computer simulations at RAND. After analyzing the results of the first experiment he determined that had a participant entered the tit for two tats strategy it would have emerged with a higher cumulative score than any other program. As a result he himself entered it with high expectations in the second tournament. Unfortunately due to the more aggressive nature of the programs entered in the second round, tit for two tats did significantly worse than tit for tat due to aggressive strategies being able to take advantage of its highly forgiving nature.[citation needed]

[edit] Real world use

[edit] Peer-to-peer file sharing
See also: BitTorrent_(protocol)#Downloading torrents and sharing files
BitTorrent peers use Tit for Tat strategy to optimize their download speed.[3] More specifically, most BitTorrent peers use a variant of Tit for two Tats which is called optimistic unchoking in BitTorrent terminology. BitTorrent peers have a limited number of upload slots to allocate to other peers. Cooperation is achieved when upload bandwidth is exchanged for download bandwidth. Consequently, when a peer's upload bandwidth is saturated, it will use a Tit for Tat strategy. Optimistic unchoking corresponds very strongly to always cooperating on the first move in prisoner’s dilemma. Periodically, a peer will allocate an upload slot to a randomly chosen peer (unchoke). This is called optimistic unchoking. This allows to search for more cooperating peers and to give a second chance to previously non-cooperating peers.

[edit] Explaining Reciprocal Altruism in Animal Communities
Studies in the prosocial behaviour of animals, have led many ethologists and evolutionary psychologists to apply Tit for Tat strategies to explain why altruism evolves in many animal communities. Evolutionary game theory, derived from the mathematical theories formalised by Von Neumann and Morgenstern (1953), was first devised by Maynard Smith(1972) and explored further in bird behaviour by Robert Hinde. Their application of game theory to the evolution of animal strategies launched an entirely new way of analysing animal behaviour.
Reciprocal altruism works in animal communities where the cost to the benefactor in any transaction of food, mating rights, nesting or territory is less than the gains to the beneficiary. The theory also holds that the act of altruism should be reciprocated if the balance of needs reverse. Mechanisms to identify and punish "cheaters" who fail to reciprocate, in effect a form of Tit for Tat, is an important mechanism to regulate reciprocal altruism .

[edit] War
The tit for tat strategy has been detected by analysts in the spontaneous non-violent behaviour, called "live and let live" that arose during the First World War. The Christmas truce of 1914 appears to be an example.

[edit] Popular culture
The tit for tat strategy was employed in an episode of Numb3rs, where FBI agents were interrogating and attempting to obtain information from an inmate on death row. The strategy was working, but the FBI would not implement a "tit for two tats".

[edit] See also



Look up tit for tat in
Wiktionary, the free dictionary.



An eye for an eye
Trigger strategy (a set of strategies of which tit for tat is a member)
Quid pro quo
Chicken (game)
Nice Guys Finish First, a documentary by Richard Dawkins that discusses tit for tat
Mutual assured destruction
Deterrence theory


[edit] References


^ Gintis, Herbert (2000). Game Theory Evolving. Princeton University Press. ISBN 0691009430. 
^ Boyd, Robert (1989). "Mistakes Allow Evolutionary Stability in the Repeated Prisoner's Dilemma Game". Journal of Theoretical Biology 136: 47–56. doi:10.1016/S0022-5193(89)80188-2. 
^ Bram Cohen, Incentives Build Robustness in BitTorrent, May 22, 2003, http://www.bittorrent.org/bittorrentecon.pdf



[edit] External links

Wired magazine story about Tit for Tat being 'defeated' by a group of collaborating programs
Explanation of Tit for tat on Australian Broadcasting Corporation
Article on Tit for Tat and its success in evolutionary cooperation








v • d • e

Topics in game theory





Definitions

Normal-form game · Extensive-form game · Cooperative game · Information set · Preference






Equilibrium concepts

Nash equilibrium · Subgame perfection · Bayesian-Nash · Perfect Bayesian · Trembling hand · Proper equilibrium · Epsilon-equilibrium · Correlated equilibrium · Sequential equilibrium · Quasi-perfect equilibrium · Evolutionarily stable strategy · Risk dominance · Pareto efficiency · Quantal response equilibrium






Strategies

Dominant strategies · Pure strategy · Mixed strategy · Tit for tat · Grim trigger · Collusion · Backward induction






Classes of games

Symmetric game · Perfect information · Dynamic game · Sequential game · Repeated game · Signaling game · Cheap talk · Zero-sum game · Mechanism design · Bargaining problem · Stochastic game · Nontransitive game · Global games






Games

Prisoner's dilemma · Traveler's dilemma · Coordination game · Chicken · Centipede game · Volunteer's dilemma · Dollar auction · Battle of the sexes · Stag hunt · Matching pennies · Ultimatum game · Minority game · Rock-paper-scissors · Pirate game · Dictator game · Public goods game · Blotto games · War of attrition · El Farol Bar problem · Cake cutting · Cournot game · Deadlock · Diner's dilemma · Guess 2/3 of the average · Kuhn poker · Nash bargaining game · Screening game · Trust game · Princess and monster game






Theorems

Minimax theorem · Purification theorem · Folk theorem · Revelation principle · Arrow's impossibility theorem






See also

Tragedy of the commons · All-pay auction · List of games in game theory









Retrieved from "http://en.wikipedia.org/wiki/Tit_for_tat"
Categories: Non-cooperative games | AltruismHidden categories: Articles needing additional references from December 2007 | All articles with unsourced statements | Articles with unsourced statements since August 2008 | Articles with unsourced statements since November 2008 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Deutsch
Español
Français
Italiano
Polski
Português









 This page was last modified on 18 March 2009, at 15:26 (UTC).
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
