













Akaike information criterion - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Akaike_information_criterion";
		var wgTitle = "Akaike information criterion";
		var wgAction = "view";
		var wgArticleId = "690512";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 279447466;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Akaike information criterion

From Wikipedia, the free encyclopedia

Jump to: navigation, search 
Akaike's information criterion, developed by Hirotsugu Akaike under the name of "an information criterion" (AIC) in 1971 and proposed in Akaike (1974), is a measure of the goodness of fit of an estimated statistical model. It is grounded in the concept of entropy, in effect offering a relative measure of the information lost when a given model is used to describe reality and can be said to describe the tradeoff between bias and variance in model construction, or loosely speaking that of precision and complexity of the model.
The AIC is not a test on the model in the sense of hypothesis testing, rather it is a tool for model selection. Given a data set, several competing models may be ranked according to their AIC, with the one having the lowest AIC being the best. From the AIC value one may infer that e.g the top three models are in a tie and the rest are far worse, but one should not assign a value above which a given model is 'rejected'.[1]




Contents


1 Definition
2 Relevance to χ2 fitting (maximum likelihood)
3 AICc and AICu
4 QAIC
5 References
6 See also
7 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Definition
In the general case, the AIC is



where k is the number of parameters in the statistical model, and L is the maximized value of the likelihood function for the estimated model.
Over the remainder of this entry, it will be assumed that the model errors are normally and independently distributed. Let n be the number of observations and RSS be



the residual sum of squares. We further assume that the variance of the model errors is unknown but equal for them all. Maximizing the likelihood with respect to this variance, the AIC becomes



This can be simplified by factoring out the term n * ln(2π). This is a constant term added to the AIC value of all the competing models. Therefore it can't affect the order in which we rank them and we can safely remove this term. When we also factor out the constant n, AIC simplifies to:



Increasing the number of free parameters to be estimated improves the goodness of fit, regardless of the number of free parameters in the data generating process. Hence AIC not only rewards goodness of fit, but also includes a penalty that is an increasing function of the number of estimated parameters. This penalty discourages overfitting. The preferred model is the one with the lowest AIC value. The AIC methodology attempts to find the model that best explains the data with a minimum of free parameters. By contrast, more traditional approaches to modeling start from a null hypothesis. The AIC penalizes free parameters less strongly than does the Schwarz criterion.
AIC judges a model by how close its fitted values tend to be to the true values, in terms of a certain expected value. But it is important to realize that the AIC value assigned to a model is only meant to rank competing models and tell you which is the best among the given alternatives. It is an error to state that a model with say AIC < 0.5 is "good" while AIC > 4 is "bad".

[edit] Relevance to χ2 fitting (maximum likelihood)
Often, one wishes to select amongst competing models where the likelihood function assumes that the underlying errors are normally distributed. This assumption leads to χ2 data fitting.
For any set of models where the number of data points, n, is the same, one can use a slightly altered AIC. For the purposes of this article, this will be called . It differs from the AIC only through an additive constant, which is a function only of n. As only differences in the AIC are relevant, this constant can be ignored.
In general least squares, the testing quantity



is  distributed, n − k being the number of degrees of freedom. Here, Q is the variance matrix of the observations. For Q = σ2I, this reduces to the previous case.  is now given by

.

This form is often convenient in that data fitting programs produce χ2 as a statistic for the fit. For models with the same number of data points, the one with the lowest  should be preferred.
Similarly, if one has available the statistic R2 ("Variance Explained"), one may write

.

The Pearson correlation r = R is a special case of this. Here, independence of the observations is assumed.

[edit] AICc and AICu
AICc is AIC with a second order correction for small sample sizes, to start with:



Since AICc converges to AIC as n gets large, AICc should be employed regardless of sample size (Burnham and Anderson, 2004).
McQuarrie and Tsai (1998: 22) define AICc as:



and propose (p. 32) the closely related measure:



McQuarrie and Tsai ground their high opinion of AICc and AICu on extensive simulation work.

[edit] QAIC
QAIC (the quasi-AIC) is defined as:



where c is a variance inflation factor. QAIC adjusts for over-dispersion or lack of fit. The small sample version of QAIC is




[edit] References

^ Burnham, Anderson, 1998, "Model Selection and Inference - A practical information-theoretic approach" ISBN 0-387-98504-2


Akaike, Hirotugu (1974). "A new look at the statistical model identification". IEEE Transactions on Automatic Control 19 (6): 716–723. doi:10.1109/TAC.1974.1100705. MR0423716. 
Burnham, K. P., and D. R. Anderson, 2002. Model Selection and Multimodel Inference: A Practical-Theoretic Approach, 2nd ed. Springer-Verlag. ISBN 0-387-95364-7.
--------, 2004. Multimodel Inference: understanding AIC and BIC in Model Selection, Amsterdam Workshop on Model Selection.
Hurvich, C. M., and Tsai, C.-L., 1989. Regression and time series model selection in small samples. Biometrika, Vol 76. pp. 297-307
McQuarrie, A. D. R., and Tsai, C.-L., 1998. Regression and Time Series Model Selection. World Scientific.


[edit] See also

Bayesian information criterion
deviance
deviance information criterion
Hannan-Quinn information criterion
Jensen-Shannon divergence
Kullback-Leibler divergence
Occam's Razor


[edit] External links

Hirotogu Akaike comments on how he arrived at the AIC in This Week's Citation Classic




Retrieved from "http://en.wikipedia.org/wiki/Akaike_information_criterion"
Categories: Regression analysis 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Deutsch
Italiano
日本語
Polski
Basa Sunda
中文









 This page was last modified on 24 March 2009, at 21:25.
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
