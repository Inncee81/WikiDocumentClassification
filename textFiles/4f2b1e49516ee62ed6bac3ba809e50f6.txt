













Character encoding - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Character_encoding";
		var wgTitle = "Character encoding";
		var wgAction = "view";
		var wgArticleId = "5295";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 279150556;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Character encoding

From Wikipedia, the free encyclopedia

Jump to: navigation, search 
"Special characters" redirects here. For the editor handbook page, see Help:Special characters.
A character encoding system consists of a code that pairs a sequence of characters from a given character set (sometimes incorrectly referred to as code page) with something else, such as a sequence of natural numbers, octets or electrical pulses, in order to facilitate the transmission of data (generally numbers and/or text) through telecommunication networks and/or storage of text in computers.




Contents


1 Terminology
2 History
3 Modern encoding model
4 Popular character encodings
5 Character encoding translation
6 See also
7 References
8 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Terminology
The terms character set and character encoding are often used interchangeably, though usually incorrectly. The term character set refers only to the set (or group) of characters (and sometimes device control codes) used by a particular encoding system, but does not include their numerical assignments nor order therein. The term character encoding includes a character set and how each character is represented within a character encoding system.
For historical reasons, MIME and systems based on it use the abbreviation charset to refer to the complete system for encoding a sequence of characters into a sequence of octets.

[edit] History
Common examples of character encoding systems include Morse code, the Baudot code, the American Standard Code for Information Interchange (ASCII) and Unicode.
Morse code was introduced in the 1840s and is used to encode each letter of the Latin alphabet and each Arabic numeral as a series of long and short presses of a telegraph key. Representations of characters encoded using Morse code varied in length.
The Baudot code was created by Émile Baudot in 1870, patented in 1874, modified by Donald Murray in 1901, and standardized by CCITT as International Telegraph Alphabet No. 2 (ITA2) in 1930.
The American Standard Code for Information Interchange (usually abbreviated ASCII) was introduced in 1963 and is a 7-bit encoding scheme used to encode letters, numerals, symbols, and device control codes as fixed-length codes using integers). IBM's Extended Binary Coded Decimal Interchange Code (usually abbreviated EBCDIC) is an 8-bit encoding scheme developed in 1963.
The limitations of such sets soon became apparent, and a number of ad-hoc methods were developed to extend them. The need to support more writing systems for different languages, including the CJK family of East Asian scripts, required support for a far larger number of characters and demanded a systematic approach to character encoding rather than the previous ad hoc approaches.
Early binary repertoires include:

I Ching (China 1122 BC - 256 BC)
Braille
International maritime signal flags
Chinese telegraph code (Hans Schjellerup, 1869, modified 1872 and following)

Encoding of Chinese characters as 4-digit decimals.




[edit] Modern encoding model
Unicode and its parallel standard, ISO 10646 Universal Character Set, which together constitute the most modern character encoding, broke away from this idea, and instead separated the ideas of what characters are available, their numbering, how those numbers are encoded as a series of "code units" (limited-size numbers), and finally how those units are encoded as a stream of octets (bytes). The idea behind this decomposition is to establish a universal set of characters that can be encoded in a variety of ways[1]. To correctly describe this model needs more precise terms than "character set" and "character encoding". The terms used in the modern model follow:
A character repertoire is the full set of abstract characters that a system supports. The repertoire may be closed, that is no additions are allowed without creating a new standard (as is the case with ASCII and most of the ISO-8859 series), or it may be open, allowing additions (as is the case with Unicode and to a limited extent the Windows code pages). The characters in a given repertoire reflect decisions that have been made about how to divide writing systems into linear information units. The basic variants of the Latin, Greek, and Cyrillic alphabets, can be broken down into letters, digits, punctuation, and a few special characters like the space, which can all be arranged in simple linear sequences that are displayed in the same order they are read. Even with these alphabets however diacritics pose a complication: they can be regarded either as part of a single character containing a letter and diacritic (known in modern terminology as a precomposed character), or as separate characters. The former allows a far simpler text handling system but the latter allows any letter/diacritic combination to be used in text. Other writing systems, such as Arabic and Hebrew, are represented with more complex character repertoires due to the need to accommodate things like bidirectional text and glyphs that are joined together in different ways for different situations.
A coded character set specifies how to represent a repertoire of characters using a number of non-negative integer codes called code points. For example, in a given repertoire, a character representing the capital letter "A" in the Latin alphabet might be assigned to the integer 65, the character for "B" to 66, and so on. A complete set of characters and corresponding integers is a coded character set. Multiple coded character sets may share the same repertoire; for example ISO/IEC 8859-1 and IBM code pages 037 and 500 all cover the same repertoire but map them to different codes. In a coded character set, each code point only represents one character.
A character encoding form (CEF) specifies the conversion of a coded character set's integer codes into a set of limited-size integer code values that facilitate storage in a system that represents numbers in binary form using a fixed number of bits (i.e. practically any computer system). For example, a system that stores numeric information in 16-bit units would only be able to directly represent integers from 0 to 65,535 in each unit, but larger integers could be represented if more than one 16-bit unit could be used. This is what a CEF accommodates: it defines a way of mapping single code point from a range of, say, 0 to 1.4 million, to a series of one or more code values from a range of, say, 0 to 65,535.
The simplest CEF system is simply to choose large enough units that the values from the coded character set can be encoded directly (one code point to one code value). This works well for coded character sets that fit in 8 bits (as most legacy non-CJK encodings do) and reasonably well for coded character sets that fit in 16 bits (such as early versions of Unicode). However, as the size of the coded character set increases (e.g. modern Unicode requires at least 21 bits/character), this becomes less and less efficient, and it is difficult to adapt existing systems to use larger code values. Therefore, most systems working with later versions of Unicode use either UTF-8, which maps Unicode code points to variable-length sequences of octets, or UTF-16/UCS-2, which maps Unicode code points to variable-length sequences of 16-bit words.
Next, a character encoding scheme (CES) specifies how the fixed-size integer codes should be mapped into an octet sequence suitable for saving on an octet-based file system or transmitting over an octet-based network. With Unicode, a simple character encoding scheme is used in most cases, simply specifying whether the bytes for each integer should be in big-endian or little-endian order (even this isn't needed with UTF-8). However, there are also compound character encoding schemes, which use escape sequences to switch between several simple schemes (such as ISO/IEC 2022), and compressing schemes, which try to minimise the number of bytes used per code unit (such as SCSU, BOCU, and Punycode).
Finally, there may be a higher level protocol which supplies additional information that can be used to select the particular variant of a Unicode character, particularly where there are regional variants that have been 'unified' in Unicode as the same character. An example is the XML attribute xml:lang.

[edit] Popular character encodings

ISO 646

ASCII


EBCDIC

CP930


ISO 8859:

ISO 8859-1 Western Europe
ISO 8859-2 Western and Central Europe
ISO 8859-3 Western Europe and South European ( Turkish, Maltese plus Esperanto )
ISO 8859-4 Western Europe and Baltic countries ( Lithuania, Estonia and Lapp )
ISO 8859-5 Cyrillic alphabet
ISO 8859-6 Arabic
ISO 8859-7 Greek
ISO 8859-8 Hebrew
ISO 8859-9 Western Europe with amended Turkish character set
ISO 8859-10 Western Europe with rationalised character set for Nordic languages, including complete Icelandic set.
ISO 8859-11 Thai
ISO 8859-13 Baltic languages plus Polish
ISO 8859-14 Celtic languages ( Irish Gaelic, Scottish, Welsh )
ISO 8859-15 Added the Euro sign and other rationalisations to ISO 8859-1
ISO 8859-16 Central European languages ( Polish, Czech, Slovenian, Slovak, Hungarian, Albanian, Romanian, German, Italian )


CP437, CP737, CP850, CP852, CP855, CP857, CP858, CP860, CP861, CP863, CP865, CP866, CP869
MS-Windows character sets:

Windows-1250 for Central European languages that use Latin script, (Polish, Czech, Slovak, Hungarian, Slovene, Serbian, Croatian, Romanian and Albanian)
Windows-1251 for Cyrillic alphabets
Windows-1252 for Western languages
Windows-1253 for Greek
Windows-1254 for Turkish
Windows-1255 for Hebrew
Windows-1256 for Arabic
Windows-1257 for Baltic languages
Windows-1258 for Vietnamese


Mac OS Roman
KOI8-R, KOI8-U, KOI7
MIK
Cork or T1
ISCII
TSCII
VISCII
JIS X 0208 is a widely deployed standard for Japanese character encoding that has several encoding forms.

Shift_JIS (Microsoft Code page 932 is a dialect of Shift_JIS)
EUC-JP
ISO-2022-JP


JIS X 0213 is an extended version of JIS X 0208.

Shift_JIS-2004
EUC-JIS-2004
ISO-2022-JP-2004


Chinese Guobiao

GB 2312
GBK (Microsoft Code page 936)
GB 18030


Taiwan Big5 (a more famous variant is Microsoft Code page 950)
Hong Kong HKSCS
KS X 1001 is a Korean double-byte character encoding standard

EUC-KR
ISO-2022-KR


Unicode (and subsets thereof, such as the 16-bit 'Basic Multilingual Plane'). See UTF-8
ANSEL or ISO/IEC 6937


[edit] Character encoding translation
As a result of having many character encoding methods in use (and the need for backward compatibility with archived data), many computer programs have been developed to translate data between encoding schemes. Some of these are cited below.
Cross-platform:

iconv – program and standardized API to convert encodings
convert_encoding.py – Python based utility to convert text files between arbitrary encodings and line endings.[2]
decodeh.py - algorithm and module to heuristically guess the encoding of a string [3]

Linux:

recode – convert file contents from one encoding to another [4]
utrac – convert file contents from one encoding to another.[5]
cstocs – convert file contents from one encoding to another
convmv – convert a filename from one encoding to another.[6]
enca – analyzes encodings for given text files/[7]

Windows:

cscvt – character set conversion tool[8]


[edit] See also

Category:Character encoding — articles related to character encoding in general
Category:Character sets — articles detailing specific character encodings
Code page — various character set encodings used by Microsoft
Windows code page — various character set encodings used by Microsoft Windows
Mojibake — character set mismap.
Alt code


[edit] References

Mackenzie, Charles E. (1980). Coded Character Sets, History and Development. Addison-Wesley. ISBN 0-201-14460-3. 


^ Unicode Technical Report N°17 - Character Encoding Model
^ Homepage of Michael Goerz - convert_encoding.py
^ decodeh - heuristically decode a string or text file
^ recode - GNU Project - Free Software Foundation (FSF)
^ Utrac Homepage
^ convmv - converts filenames from one encoding to another
^ Extremely Naive Charset Analyser
^ Character Set Converter


[edit] External links

Character sets registered by Internet Assigned Numbers Authority
Unicode Technical Report #17: Character Encoding Model








v • d • e

Character encodings





ASCII • Baudot code • Code page • EBCDIC • Fieldata • Morse code • Unicode





ASCII variants

ATASCII • Galaksija • ISO/IEC 646 • PETSCII • YUSCII • ZX Spectrum character set






Extended ASCII

ArmSCII • Iran System • ISCII • ISO/IEC 8859 • ISO/IEC 8859-1 • KOI8 • Kamenický • Mazovia • Mac OS • TSCII • VISCII • Windows code pages






ASCII-related

ASCII art • ASCII Ribbon Campaign • Bob Bemer • Braille ASCII • Control characters






Unicode

GB 18030 • Han unification • Universal Character Set • UTF-8 • UTF-16/UCS-2 • UTF-32/UCS-4






Unicode-related

UTF-7 • UTF-9 and UTF-18 • UTF-EBCDIC • TRON









Retrieved from "http://en.wikipedia.org/wiki/Character_encoding"
Categories: Character encoding 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Asturianu
Bân-lâm-gú
Česky
Dansk
Deutsch
Español
Français
Galego
한국어
Bahasa Indonesia
Italiano
עברית
Latviešu
日本語
‪Norsk (nynorsk)‬
Polski
Português
Русский
Svenska
ไทย
Українська
中文









 This page was last modified on 23 March 2009, at 14:10.
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
