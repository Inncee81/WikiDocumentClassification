













Singularitarianism - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Singularitarianism";
		var wgTitle = "Singularitarianism";
		var wgAction = "view";
		var wgArticleId = "516138";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 283023488;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Singularitarianism

From Wikipedia, the free encyclopedia

Jump to: navigation, search 


Part of Ideology series on


Transhumanism
(humanist philosophies)





Ideologies



Abolitionism
Democratic transhumanism
Extropianism
Immortalism
Libertarian transhumanism
Postgenderism
Singularitarianism
Technogaianism



Related articles



Transhumanism in fiction
Transhumanist art
List of transhumanists



Organizations



Applied Foresight Network
Alcor Life Extension Foundation
Foresight Institute
Humanity+
Immortality Institute
Singularity Institute for Artificial Intelligence



Transhumanism Portal · v • d • e 


Singularitarianism is a moral philosophy based upon the belief that a technological singularity — the technological creation of smarter-than-human intelligence — is possible, and advocating deliberate action to bring it into effect and ensure its safety.
While many futurists and transhumanists speculate on the possibility and nature of this technological development (often referred to as the Singularity), Singularitarians believe it is not only possible, but desirable if, and only if, guided safely. Accordingly, they might sometimes "dedicate their lives" to acting in ways they believe will contribute to its safe implementation.
The term "singularitarian" was originally defined by Extropian Mark Plus in 1991 to mean "one who believes the concept of a Singularity". This term has since been redefined to mean "Singularity activist" or "friend of the Singularity"; that is, one who acts so as to bring about the Singularity.[1]
Ray Kurzweil, the author of the book The Singularity is Near, defines a Singularitarian as someone "who understands the Singularity and who has reflected on its implications for his or her own life".[2]




Contents


1 Beliefs
2 Criticism
3 See also
4 References
5 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Beliefs
In the 1980s and 1990s, prior to Singularitarianism being articulated as a coherent ideology, belief in the coming of the Singularity was adopted and expressed by a growing minority of computer scientists and technical journalists:


It feels like something big is about to happen: graphs show us the yearly growth of populations, atmospheric concentrations of carbon dioxide, Net addresses, and Mbytes per dollar. They all soar up to form an asymptote just beyond the turn of the century: The Singularity. The end of everything we know. The beginning of something we may never understand.

—Danny Hillis, The Millennium Clock (1995, Wired magazine)

In his 2000 essay, "Singularitarian Principles", Eliezer Yudkowsky writes that there are four qualities that define a Singularitarian:[3]

A Singularitarian believes that the Singularity is possible and desirable.
A Singularitarian actually works to bring about the Singularity.
A Singularitarian views the Singularity as an entirely secular, non-mystical process — not the culmination of any form of religious prophecy or destiny.
A Singularitarian believes the Singularity should benefit the entire world, and should not be a means to benefit any specific individual or group.

In June 2000 Eliezer Yudkowsky, Brian Atkins and Sabine Atkins founded the Singularity Institute for Artificial Intelligence to work towards the creation of self-improving Friendly AI. The Singularity Institute's writings argue for the idea that an AI with the ability to improve upon its own design (Seed AI) would rapidly lead to superintelligence. Singularitarians believe that reaching the Singularity swiftly and safely is the best possible way to minimize net existential risk.
Many believe a technological singularity is possible without adopting Singularitarianism as a moral philosophy. Although the exact numbers are hard to quantify, Singularitarianism is presently a small movement. Other prominent Singularitarians include Ray Kurzweil and Nick Bostrom.

[edit] Criticism
Often ridiculing the Singularity as "the Rapture for nerds", many critics have dismissed singularitarianism as a pseudoreligion of fringe science.[4] However, some green anarchist militants have taken singularitarian rhetoric seriously enough to have called for violent direct action to stop the Singularity.[5]

[edit] See also

Extropianism
Seed AI — a theory closely associated with Singularitarianism
Simulated reality — analysis of potential technologically based reality


[edit] References


^ http://www.extropy.org/neologo.htm#s Neologisms of Extropy
^ The Singularity is Near - Chapter One (The Six Epochs)
^ Singularitarian Principles"
^ Horgan, John (2008). The Consciousness Conundrum. http://www.spectrum.ieee.org/jun08/6280. Retrieved on 2008-12-17. 
^ mosh@terran hacker corps (2005). A Singular Rapture. http://www.greenanarchy.org/index.php?action=viewwritingdetail&writingId=182. Retrieved on 2008-12-11. 



[edit] External links

Why Work Towards the Singularity? by Eliezer Yudkowsky
Ethical Issues in Advanced Artificial Intelligence by Nick Bostrom




Retrieved from "http://en.wikipedia.org/wiki/Singularitarianism"
Categories: Singularitarianism | Technology neologisms | Transhumanism 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Italiano
Lietuvių









 This page was last modified on 10 April 2009, at 18:38 (UTC).
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
