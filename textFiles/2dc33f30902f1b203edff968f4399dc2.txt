













Trie - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Trie";
		var wgTitle = "Trie";
		var wgAction = "view";
		var wgArticleId = "31274";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 279851860;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
/*<![CDATA[*/
.source-python {line-height: normal;}
.source-python li, .source-python pre {
	line-height: normal; border: 0px none white;
}
/**
 * GeSHi Dynamically Generated Stylesheet
 * --------------------------------------
 * Dynamically generated stylesheet for python
 * CSS class: source-python, CSS id: 
 * GeSHi (C) 2004 - 2007 Nigel McNie (http://qbnz.com/highlighter)
 */
.source-python .de1, .source-python .de2 {font-family: 'Courier New', Courier, monospace; font-weight: normal;}
.source-python  {}
.source-python .head {}
.source-python .foot {}
.source-python .imp {font-weight: bold; color: red;}
.source-python .ln-xtra {color: #cc0; background-color: #ffc;}
.source-python li {font-family: 'Courier New', Courier, monospace; color: black; font-weight: normal; font-style: normal;}
.source-python li.li2 {font-weight: bold;}
.source-python .kw1 {color: #ff7700;font-weight:bold;}
.source-python .kw2 {color: #008000;}
.source-python .kw3 {color: #dc143c;}
.source-python .kw4 {color: #0000cd;}
.source-python .co1 {color: #808080; font-style: italic;}
.source-python .coMULTI {color: #808080; font-style: italic;}
.source-python .es0 {color: #000099; font-weight: bold;}
.source-python .br0 {color: #66cc66;}
.source-python .st0 {color: #483d8b;}
.source-python .nu0 {color: #ff4500;}
.source-python .me1 {color: black;}

/*]]>*/

/*<![CDATA[*/
@import "/w/index.php?title=MediaWiki:Geshi.css&usemsgcache=yes&action=raw&ctype=text/css&smaxage=2678400";
/*]]>*/
 <!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Trie

From Wikipedia, the free encyclopedia

Jump to: navigation, search 




A trie for keys "A", "to", "tea", "ted", "ten", "i", "in", and "inn".


In computer science, a trie, or prefix tree, is an ordered tree data structure that is used to store an associative array where the keys are usually strings. Unlike a binary search tree, no node in the tree stores the key associated with that node; instead, its position in the tree shows what key it is associated with. All the descendants of a node have a common prefix of the string associated with that node, and the root is associated with the empty string. Values are normally not associated with every node, only with leaves and some inner nodes that correspond to keys of interest.
The term trie comes from "retrieval." Following the etymology, the inventor, Edward Fredkin, pronounces it [tɹi] ("tree").[1] However, it is pronounced [tɹaɪ] ("try") by other authors.[2]
In the example shown, keys are listed in the nodes and values below them. Each complete English word has an (arbitrary) integer value associated with it. A trie can be seen as a deterministic finite automaton, although the symbol on each edge is often implicit in the order of the branches.
It is not necessary for keys to be explicitly stored in nodes. (In the figure, words are shown only to illustrate how the trie works.)
Though it is most common, tries need not be keyed by character strings. The same algorithms can easily be adapted to serve similar functions of ordered lists of any construct, e.g., permutations on a list of digits, permutations on a list of shapes, etc.




Contents


1 Advantages and drawbacks, relative to binary search tree
2 Applications

2.1 As replacement of other data structures
2.2 Dictionary representation
2.3 Algorithms
2.4 Sorting
2.5 Full text search
2.6 Compressing tries


3 See also
4 External links
5 References





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Advantages and drawbacks, relative to binary search tree
The following are the main advantages of tries over binary search trees (BSTs):

Looking up keys is faster. Looking up a key of length m takes worst case O(m) time. A BST performs O(log n) comparisons of keys, where n is the number of elements in the tree, because lookups depend on the depth of the tree, which is logarithmic in the number of keys if the tree is balanced. Hence in the worst case, a BST takes O(m log n) time. Moreover, in the worst case log(n) will approach m. Also, the simple operations tries use during lookup, such as array indexing using a character, are fast on real machines.
Tries can require less space when they contain a large number of short strings, because the keys are not stored explicitly and nodes are shared between keys with common initial subsequences.
Tries help with longest-prefix matching, where we wish to find the key sharing the longest possible prefix of characters all unique.


[edit] Applications

[edit] As replacement of other data structures
As mentioned, a trie has a number of advantages over binary search trees.[3] A trie can also be used to replace a hash table, over which it has the following advantages:

Looking up data in a trie is faster in the worst case, O(m) time, compared to an imperfect hash table. An imperfect hash table can have key collisions. A key collision is the hash function mapping of different keys to the same position in a hash table. The worst-case lookup speed in an imperfect hash table is O(N) time, but far more typically is O(1), with O(m) time spent evaluating the hash.
There are no collisions of different keys in a trie.
Buckets in a trie which are analogous to hash table buckets that store key collisions are only necessary if a single key is associated with more than one value.
There is no need to provide a hash function or to change hash functions as more keys are added to a trie.
A trie can provide an alphabetical ordering of the entries by key.

Tries do have some drawbacks as well:

Tries can be slower in some cases than hash tables for looking up data, especially if the data is directly accessed on a hard disk drive or some other secondary storage device where the random access time is high compared to main memory.[4]
It is not easy to represent all keys as strings, such as floating point numbers, which can have multiple string representations for the same floating point number, e.g. 1, 1.0, 1.00, +1.0, etc.


[edit] Dictionary representation
A common application of a trie is storing a dictionary, such as one found on a mobile telephone. Such applications take advantage of a trie's ability to quickly search for, insert, and delete entries; however, if storing dictionary words is all that is required (i.e. storage of information auxiliary to each word is not required), a minimal acyclic deterministic finite automaton would use less space than a trie.[citation needed]
Tries are also well suited for implementing approximate matching algorithms, including those used in spell checking software.

[edit] Algorithms
We can describe trie lookup (and membership) easily. Given a recursive trie type, storing an optional value at each node, and a list of children tries, indexed by the next character, (here, represented as a Haskell data type):

data Trie a =
     Trie { value    :: Maybe a
          , children :: [(Char,Trie a)] }


We can lookup a value in the trie as follows:

   find :: String -> Trie a -> Maybe a
   find []     t = value t
   find (k:ks) t = case lookup k (children t) of
                       Nothing  -> Nothing
                       Just t'  -> find ks t'


In an imperative style, and assuming an appropriate data type in place, we can describe the same algorithm in Python (here, specifically for testing membership). Note that children is map of a node's children; and we say that a "terminal" node is one which contains a valid word.


 def isKeyInTrie(node, key):
   if len(key) == 0:                 # base case: key is an empty string
     return node.isTerminal()        # we have a match if the node is terminal
   c = key[0]                        # first character in key
   if not node.children.hasKey(c):   # no child node?
     return False                    # key is not empty, so there is no match
   child = node.children[c]          # get child node  
   tail = key[1:]                    # the rest of the key after first character
   return isKeyInTrie(child, tail)   # recurse


[edit] Sorting
Lexicographic sorting of a set of keys can be accomplished with a simple trie-based algorithm as follows:

Insert all keys in a trie.
Output all keys in the trie by means of pre-order traversal, which results in output that is in lexicographically increasing order, or post-order traversal, which results in output that is in lexicographically decreasing order. Pre-order traversal and post-order traversal are kinds of depth-first traversal. In-order traversal is another kind of depth-first traversal that is more appropriate for outputting the values that are in a binary search tree rather than a trie.

This algorithm is a form of radix sort.
A trie forms the fundamental data structure of Burstsort; currently (2007) the fastest known, memory/cache-based, string sorting algorithm.[5]
A parallel algorithm for sorting N keys based on tries is O(1) if there are N processors and the length of the keys have a constant upper bound. There is the potential that the keys might collide by having common prefixes or by being identical to one another, reducing or eliminating the speed advantage of having multiple processors operating in parallel.

[edit] Full text search
A special kind of trie, called a suffix tree, can be used to index all suffixes in a text in order to carry out fast full text searches.

[edit] Compressing tries
When the trie is mostly static, i.e. all insertions or deletions of keys from a prefilled trie are disabled and only lookups are needed, and when the trie nodes are not keyed by node specific data (or if the node's data is common) it is posible to compress the trie representation by merging the common branches.
This application is typically used for compressing lookup tables when the total set of stored keys is very sparse within their representation space.
For example it may be used to represent sparse bitsets (i.e. subsets of a much fixed enumerable larger set) using a trie keyed by the bit element position within the full set, with the key created from the string of bits needed to encode the integral position of each element. The trie will then have a very degenerate form with many missing branches, and compression becomes possible by storing the leaf nodes (set segments with fixed length) and combining them after detecting the repetition of common patterns or by filling the unused gaps.
Such compression is also typically used, in the implementation of the various fast lookup tables needed to retrieve Unicode character properties (for example to represent case mapping tables, or lookup tables containing the combination of base and combining characters needed to support Unicode normalization). For such application, the representation is similar to transforming a very large unidimensional sparse table into a multidimensional matrix, and then using the coordinates in the hyper-matrix as the string key of an uncompressed trie. The compression will then consist into detecting and merging the common columns within the hyper-matrix to compress the last dimension in the key; each dimension of the hypermatrix stores the start position within a storage vector of the next dimension for each coordinate value, and the resulting vector is itself compressible when it is also sparse, so each dimension (associated to a layer level in the trie) is compressed separately.
Some implementations do support such data compression within dynamic sparse tries and allow insertions and deletions in compressed tries, but generally this has a significant cost when compressed segments need to be split or merged, and some tradeoff has to be made between the smallest size of the compressed trie and the speed of updates, by limiting the range of global lookups for comparing the common branches in the sparse trie.
The result of such compression may look similar to trying to transform the trie into a directed acyclic graph (DAG), because the reverse transform from a DAG to a trie is obvious and always possible, however it is constrained by the form of the key chosen to index the nodes.

[edit] See also




Radix tree
Directed acyclic word graph (aka DAWG)
Ternary search tries
Acyclic deterministic finite automata




Deterministic finite automata
Judy array
Search algorithm
Extendible hashing




Prefix Hash Tree
Burstsort
Luleå algorithm
Huffman coding





[edit] External links

NIST's Dictionary of Algorithms and Data Structures: Trie
Tries by Lloyd Allison
Using Tries Topcoder tutorial
An Implementation of Double-Array Trie
de la Briandais Tree
Discussing a trie implementation in Lisp
ServerKit "parse trees" implement a form of Trie in C


[edit] References

^ Paul E. Black. Dictionary of Algorithms and Data Structures, NIST. http://www.nist.gov/dads/HTML/trie.html
^ Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching, Second Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Section 6.3: Digital Searching, page 492.
^ Jon Bentley and Robert Sedgewick (1998). "Ternary Search Trees". Dr. Dobbs Journal. http://www.ddj.com/windows/184410528. 
^ Edward Fredkin (1960). "Trie Memory". Communications of the ACM 3 (9): 490. doi:10.1145/367390.367400. 
^ "Cache-Efficient String Sorting Using Copying" (PDF). http://www.cs.mu.oz.au/~rsinha/papers/SinhaRingZobel-2006.pdf. Retrieved on 2008-11-15. 


de la Briandais, R. (1959), "File Searching Using Variable Length Keys", Proceedings of the Western Joint Computer Conference: 295–298 




Retrieved from "http://en.wikipedia.org/wiki/Trie"
Categories: Trees (structure) | Data structuresHidden categories: All articles with unsourced statements | Articles with unsourced statements since February 2009 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Català
Česky
Deutsch
Español
Français
Galego
日本語
Polski
Português
Русский
Українська
中文









 This page was last modified on 26 March 2009, at 19:09 (UTC).
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
