













Moment (mathematics) - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Moment_(mathematics)";
		var wgTitle = "Moment (mathematics)";
		var wgAction = "view";
		var wgArticleId = "368684";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 281582200;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Moment (mathematics)

From Wikipedia, the free encyclopedia

Jump to: navigation, search 
"Second moment" redirects here. For the technique in probability theory, see Second moment method.
See also: Moment (physics)
The concept of moment in mathematics evolved from the concept of moment in physics. The nth moment of a real-valued function f(x) of a real variable about a value c is



It is possible to define moments for random variables in a more general fashion than moments for real values. See Moments in metric spaces.
The moments about zero[clarification needed] are usually referred to simply as the moments of a function. Usually, except in the special context of the problem of moments, the function will be a probability density function. The nth moment (about zero) of a probability density function f(x) is the expected value of Xn. The moments about its mean μ are called central moments; these describe the shape of the function, independently of translation.
If f is a probability density function, then the value integral above is called the nth moment of the probability distribution. More generally, if F is a cumulative probability distribution function of any probability distribution, which may not have a density function, then the nth moment of the probability distribution is given by the Riemann-Stieltjes integral



where X is a random variable that has this distribution and E the expectation operator.
When



then the moment is said not to exist. If the nth moment about any point exists, so does (n − 1)th moment, and all lower-order moments, about every point.




Contents


1 Significance of the moments

1.1 Variance

1.1.1 Normalized moments


1.2 Skewness
1.3 Kurtosis


2 Cumulants
3 Sample moments
4 Problem of moments
5 Partial moments
6 Moments in metric spaces
7 See also
8 External links





//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Significance of the moments




Increasing each of the first four moments in turn whilst keeping the others constant, for a discrete uniform distribution with four values.


The first moment about zero, if it exists, is the expectation of X, i.e. the mean of the probability distribution of X, designated μ. In higher orders, the central moments are more interesting than the moments about zero.
The nth central moment of the probability distribution of a random variable X is



The first central moment is thus 0.

[edit] Variance
The second central moment is the variance, the positive square root of which is the standard deviation, σ.

[edit] Normalized moments
The normalized nth central moment or standardized moment is the nth central moment divided by σn; the normalized nth central moment of x = E((x − μ)n)/σn. These normalized central moments are dimensionless quantities, which represent the distribution independently of any linear change of scale.

[edit] Skewness
The third central moment is a measure of the lopsidedness of the distribution; any symmetric distribution will have a third central moment, if defined, of zero. The normalized third central moment is called the skewness, often γ. A distribution that is skewed to the left (the tail of the distribution is heavier on the right) will have a negative skewness. A distribution that is skewed to the right (the tail of the distribution is heavier on the left), will have a positive skewness.
For distributions that are not too different from the normal distribution, the median will be somewhere near μ − γσ/6; the mode about μ − γσ/2.[citation needed]

[edit] Kurtosis
The fourth central moment is a measure of whether the distribution is tall and skinny or short and squat, compared to the normal distribution of the same variance. Since it is the expectation of a fourth power, the fourth central moment, where defined, is always positive; and except for a point distribution, it is always strictly positive. The fourth central moment of a normal distribution is 3σ4.
The kurtosis κ is defined to be the normalized fourth central moment minus 3. (Equivalently, as in the next section, it is the fourth cumulant divided by the square of the variance.) Some authorities do not subtract three, but it is usually more convenient to have the normal distribution at the origin of coordinates. If a distribution has a peak at the mean and long tails, the fourth moment will be high and the kurtosis positive; and conversely; thus, bounded distributions tend to have low kurtosis.
The kurtosis can be positive without limit, but κ must be greater than or equal to γ2 − 2; equality only holds for binary distributions. For unbounded skew distributions not too far from normal, κ tends to be somewhere in the area of γ2 and 2γ2.
The inequality can be proven by considering



where T = (X − μ)/σ. This is the expectation of a square, so it is non-negative whatever a is; on the other hand, it's also a quadratic equation in a. Its discriminant must be non-positive, which gives the required relationship.

[edit] Cumulants


Main article: cumulant


The first moment and the second and third unnormalized central moments are linear in the sense that if X and Y are independent random variables then



and



and



(These can also hold for variables that satisfy weaker conditions than independence. The first always holds; if the second holds, the variables are called uncorrelated).
In fact, these are the first three cumulants and all cumulants share this linearity property.

[edit] Sample moments
The moments of a population can be estimated using the sample k-th moment



applied to a sample X1,X2,..., Xn drawn from the population.
It can be trivially shown that the expected value of the sample moment is equal to the k-th moment of the population, if that moment exists, for any sample size n. It is thus an unbiased estimator.

[edit] Problem of moments
The problem of moments seeks characterizations of sequences { μ′n : n = 1, 2, 3, ... } that are sequences of moments of some function f.

[edit] Partial moments
Partial moments are sometimes referred to as "one-sided moments." The nth order lower and upper partial moments with respect to a reference point r may be expressed as




Partial moments are normalized by being raised to the power 1/n. The upside potential ratio may be expressed as a ratio of a first-order upper partial moment to a normalized second-order lower partial moment.

[edit] Moments in metric spaces
Let (M, d) be a metric space, and let B(M) be the Borel σ-algebra on M, the σ-algebra generated by the d-open subsets of M. (For technical reasons, it is also convenient to assume that M is a separable space with respect to the metric d.) Let 1 ≤ p ≤ +∞.
The pth moment of a measure μ on the measurable space (M, B(M)) about a given point x0 in M is defined to be



μ is said to have finite pth moment if the pth moment of μ about x0 is finite for some x0 ∈ M.
This terminology for measures carries over to random variables in the usual way: if (Ω, Σ, P) is a probability space and X : Ω → M is a random variable, then the pth moment of X about x0 ∈ M is defined to be



and X has finite pth moment if the pth moment of X about x0 is finite for some x0 ∈ M.

[edit] See also

Hamburger moment problem
Hausdorff moment problem
Image moments
Method of moments
Second moment method
Standardized moment
Stieltjes moment problem
Taylor expansions for the moments of functions of random variables


[edit] External links

Mathworld Website
Higher Moments








v • d • e

Theory of probability distributions






probability mass function (pmf) · probability density function (pdf) · cumulative distribution function (cdf) · quantile function








raw moment · central moment · mean · variance · standard deviation · skewness · kurtosis







moment-generating function (mgf) · characteristic function · probability-generating function (pgf) · cumulant













v • d • e

Statistics





Design of experiments

Population • Sampling • Stratified sampling • Replication • Blocking






Sample size estimation

Null hypothesis • Alternative hypothesis • Type I and Type II errors • Statistical power • Effect size • Standard error






Descriptive statistics





Continuous data






Location


Mean (Arithmetic, Geometric, Harmonic) • Median • Mode







Dispersion


Range • Standard deviation • Coefficient of variation • Percentile







Moments


Variance • Semivariance • Skewness • Kurtosis










Categorical data


Frequency • Contingency table









Inferential statistics

Bayesian inference • Frequentist inference • Hypothesis testing • Significance • P-value • Interval estimation • Confidence interval • Meta-analysis






General estimation

Bayesian estimator • Maximum likelihood • Method of moments • Minimum distance • Maximum spacing






Specific tests

Z-test (normal) • Student's t-test • Chi-square test • F-test • Sensitivity and specificity






Survival analysis

Survival function • Kaplan-Meier • Logrank test • Failure rate • Proportional hazards models






Correlation

Pearson product-moment correlation coefficient • Rank correlation (Spearman's rho, Kendall's tau) • Confounding variable






Linear models

General linear model • Generalized linear model • Analysis of variance • Analysis of covariance






Regression analysis

Linear regression • Nonlinear regression • Nonparametric regression • Semiparametric regression • Logistic regression






Statistical graphics

Bar chart • Biplot • Box plot • Control chart • Forest plot • Histogram • Q-Q plot • Run chart • Scatter plot • Stemplot






History

History of statistics • Founders of statistics • Timeline of probability and statistics






Publications

Journals in statistics • Important publications






Category • Portal • Topic outline • List of topics








Retrieved from "http://en.wikipedia.org/wiki/Moment_(mathematics)"
Categories: Probability theory | Mathematical analysis | Theory of probability distributionsHidden categories: All pages needing cleanup | Wikipedia articles needing clarification from March 2009 | All articles with unsourced statements | Articles with unsourced statements since February 2009 | Statistics articles with navigational template | Statistics articles needing expert attention 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


Deutsch
Français
Italiano
Magyar
日本語
Русский
Svenska
中文









 This page was last modified on 3 April 2009, at 21:59 (UTC).
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
