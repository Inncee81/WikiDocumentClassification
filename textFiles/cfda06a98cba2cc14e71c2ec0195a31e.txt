













Artificial consciousness - Wikipedia, the free encyclopedia














/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Artificial_consciousness";
		var wgTitle = "Artificial consciousness";
		var wgAction = "view";
		var wgArticleId = "195552";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 279269726;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/
<!-- wikibits js -->



/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/ 
<!-- site js -->






if (wgNotice != '') document.writeln(wgNotice); Artificial consciousness

From Wikipedia, the free encyclopedia

Jump to: navigation, search 





This article may require cleanup to meet Wikipedia's quality standards. Please improve this article if you can. (September 2007)







This article is in need of attention from an expert on the subject. WikiProject Philosophy or the Philosophy Portal may be able to help recruit one. (November 2008)


Artificial consciousness (AC), also known as machine consciousness (MC) or synthetic consciousness, is a field related to artificial intelligence and cognitive robotics whose aim is to define that which would have to be synthesized were consciousness to be found in an engineered artifact. (Aleksander 1995)
Neuroscience hypothesizes that consciousness is generated by the interoperation of various parts of the brain, called the neural correlates of consciousness or NCC. Proponents of AC believe computers can emulate this interoperation, which is not yet fully understood.




Contents


1 Consciousness in digital computers
2 Schools of thought
3 Artificial consciousness as a field of study

3.1 Programming approaches

3.1.1 Franklin’s Intelligent Distribution Agent
3.1.2 Ron Sun's cognitive architecture CLARION


3.2 Neural network approaches

3.2.1 Haikonen’s cognitive architecture
3.2.2 Takeno's self-awareness research
3.2.3 Aleksander's impossible mind




4 Testing for artificial consciousness
5 The ethics of artificial consciousness
6 Artificial consciousness in literature and movies
7 See also
8 References
9 Further reading
10 External links

10.1 Open Source Software Projects







//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>


[edit] Consciousness in digital computers
There are various aspects of consciousness generally deemed necessary for a machine to be artificially conscious. A variety of functions in which consciousness plays a role were suggested by Bernard Baars (Baars, 1988) and others. The functions of consciousness suggested by Bernard Baars are Definition and Context Setting, Adaptation and Learning, Editing, Flagging and Debugging, Recruiting and Control, Prioritizing and Access-Control, Decision-making or Executive Function, Analogy-forming Function, Metacognitive and Self-monitoring Function, Autoprogramming and Self-maintenance Function, and Definitional and Context-setting Function. Igor Aleksander suggested 12 principles for Artificial Consciousness (Aleksander, 1995) and these are: The Brain is a State Machine, Inner Neuron Partitioning, Conscious and Unconscious States, Perceptual Learning and Memory, Prediction, The Awareness of Self, Representation of Meaning, Learning Utterances, Learning Language, Will, Instinct and Emotion. The aim of AC is to define whether and how these and other aspects of consciousness can be synthesized in an engineered artefact such as digital computer. This list is not exhaustive; there are many others not covered.

Awareness

Awareness could be one required aspect, but there are many problems with the exact definition of awareness. The results of the experiments of neuroscanning on monkeys suggest that a process, not a state or object activates neurons [1]. For such reaction there must be created a model of the process based on the information received through the senses, creating model in such a way demands a lot of flexibility, and is also useful for making predictions.

Learning

Learning is also considered necessary for AC. By Bernard Baars, conscious experience is needed to represent and adapt to novel and significant events (Baars, 1988). By Axel Cleeremans and Luis Jiménez, learning is defined as “a set of philogenetically [sic] advanced adaptation processes that critically depend on an evolved sensitivity to subjective experience so as to enable agents to afford flexible control over their actions in complex, unpredictable environments” (Cleeremans, 2001).

Anticipation

The ability to predict (or anticipate) foreseeable events is considered important for AC by Igor Aleksander (Aleksander, 1995). The emergentist multiple drafts principle proposed by Daniel Dennett in Consciousness Explained may be useful for prediction: It involves the evaluation and selection of the most appropriate "draft" to fit the current environment.
By Igor Aleksander, relationships between world states are mirrored in the state structure of the conscious organism enabling the organism to predict events (Aleksander, 1995). An artificially conscious machine should be able to anticipate events correctly in order to be ready to respond to them when they occur. The implication here is that the machine needs real-time components, making it possible to demonstrate that it possesses artificial consciousness in the present and not just in the past. In order to do this, the machine being tested must operate coherently in a novel environment, to simulate the real world.

Subjective experience

Subjective experience or qualia is widely considered to be the hard problem of consciousness. Indeed, it is held to pose a challenge to physicalism, let alone computationalism. On the other hand, there is a similar problem with uncertainty principle in physics, which has not made the research in physics impossible.

[edit] Schools of thought
Debate about whether a machine could be conscious is usually framed within the philosophical conflict between monism and dualism. Dualists believe that there is something non-physical about consciousness whilst monists hold that all things are monistic (eg physical), hence the latter tend to support the idea of machine consciousness whereas the former tend to oppose it.
There are several commonly stated views regarding the plausibility and capability of AC, and the relationship between AC and natural consciousness. Some say that a thermostat is really conscious, but they do not claim the thermostat is capable of an appreciation of music. In an interview [2] David Chalmers called his statement that thermostat is conscious "very speculative" and he is not a keen proponent of panpsychism. (Chalmers 1996, p. 298) Interpretations like that are possible because of deliberately loose definitions, but tend to be too restrictive to have any significant intellectual value.
According to the nihilistic view, consciousness is just a word attributed to things that appear to make their own choices and perhaps things that are too complex for our mind to comprehend. Things seem to be conscious, but that is just because our ethical attitudes require a conscious-not conscious distinction, or because of our empathy with other entities. Consciousness is an optional perspective or social construct. (Compare with Daniel Dennett's "intentional stance", and eliminativism). The nihilistic view is in essence just another form of homunculus fallacy and thus valid whenever there is a lack of proper explanation.

[edit] Artificial consciousness as a field of study
Artificial consciousness research aims to create and study artificially conscious systems in order to understand corresponding natural mechanisms. Some researchers believe that a sufficiently sophisticated program will instantiate consciousness while others believe that a more brain-like, neural network approach is required.

[edit] Programming approaches

[edit] Franklin’s Intelligent Distribution Agent
Stan Franklin (1995, 2003) defines an autonomous agent as possessing functional consciousness when it is capable of several of the functions of consciousness as identified by Bernard Baars’ Global Workspace Theory (Baars 1988), (Baars 1997). His brain child IDA (Intelligent Distribution Agent) is a software implementation of GWT, which makes it functionally conscious by definition. IDA’s task is to negotiate new assignments for sailors in the US Navy after they end a tour of duty, by matching each individual’s skills and preferences with the Navy’s needs. IDA interacts with Navy databases and communicates with the sailors via natural language email dialog while obeying a large set of Navy policies. The IDA computational model was developed during 1996-2001 at Stan Franklin’s "Conscious" Software Research Group at the University of Memphis. It "consists of approximately a quarter-million lines of Java code, and almost completely consumes the resources of a 2001 high-end workstation." It relies heavily on codelets, which are "special purpose, relatively independent, mini-agent[s] typically implemented as a small piece of code running as a separate thread." In IDA’s top-down architecture, high-level cognitive functions are explicitly modeled; see Franklin (1995) and Franklin (2003) for details. While IDA is functionally conscious by definition, Franklin does “not attribute phenomenal consciousness to his own 'conscious' software agent, IDA, in spite of her many human-like behaviours. This in spite of watching several US Navy detailers repeatedly nodding their heads saying 'Yes, that’s how I do it' while watching IDA’s internal and external actions as she performs her task."

[edit] Ron Sun's cognitive architecture CLARION
CLARION posits a two-level representation that explains the distinction between conscious and unconscious mental processes.
CLARION has been successful in accounting for a variety of psychological data. A number of well-known skill learning tasks have been simulated using CLARION that span the spectrum ranging from simple reactive skills to complex cognitive skills. The tasks include serial reaction time (SRT) tasks, artificial grammar learning (AGL) tasks, process control (PC) tasks, the categorical inference (CI) task, the alphabetical arithmetic (AA) task, and the Tower of Hanoi (TOH) task (Sun 2002). Among them, SRT, AGL, and PC are typical implicit learning tasks, very much relevant to the issue of consciousness as they operationalized the notion of consciousness in the context of psychological experiments .
The simulations using CLARION provide detailed, process-based interpretations of experimental data related to consciousness, in the context of a broadly scoped cognitive architecture and a unified theory of cognition. Such interpretations are important for a precise, process-based understanding of consciousness and other aspects of cognition, leading up to better appreciations of the role of consciousness in human cognition (Sun 1999). CLARION also makes quantitative and qualitative predictions regarding cognition in the areas of memory, learning, motivation, meta-cognition, and so on. These predictions either have been experimentally tested already or are in the process of being tested.

[edit] Neural network approaches

[edit] Haikonen’s cognitive architecture
Pentti Haikonen (2003) considers classical rule-based computing inadequate for achieving AC: "the brain is definitely not a computer. Thinking is not an execution of programmed strings of commands. The brain is not a numerical calculator either. We do not think by numbers." Rather than trying to achieve mind and consciousness by identifying and implementing their underlying computational rules, Haikonen proposes "a special cognitive architecture to reproduce the processes of perception, inner imagery, inner speech, pain, pleasure, emotions and the cognitive functions behind these. This bottom-up architecture would produce higher-level functions by the power of the elementary processing units, the artificial neurons, without algorithms or programs". Haikonen believes that, when implemented with sufficient complexity, this architecture will develop consciousness, which he considers to be "a style and way of operation, characterized by distributed signal representation, perception process, cross-modality reporting and availability for retrospection." Haikonen is not alone in this process view of consciousness, or the view that AC will spontaneously emerge in autonomous agents that have a suitable neuro-inspired architecture of complexity; these are shared by many, e.g. Freeman (1999) and Cotterill (2003). A low-complexity implementation of the architecture proposed by Haikonen (2003) was reportedly not capable of AC, but did exhibit emotions as expected.

[edit] Takeno's self-awareness research
Self-awareness in robots is being investigated by Junichi Takeno [3] at Meiji University in Japan. Takeno is asserting that he has developed a robot capable of discriminating between a self-image in a mirror and any other having an identical image to it[4][5], and this claim has been already reviewed. (Takeno, Inaba & Suzuki 2005)

[edit] Aleksander's impossible mind
Igor Aleksander, emeritus professor of Neural Systems Engineering at Imperial College, has extensively researched artificial neural networks and claims in his book Impossible Minds: My neurons, My Consciousness that the principles for creating a conscious machine already exist but that it would take forty years to train such a machine to understand language.[1] Whether this is true remains to be demonstrated and the basic principle stated in Impossible minds: that the brain is a neural state machine is open to doubt.[2]

[edit] Testing for artificial consciousness
Unless objective criteria are being proposed as prerequisites for testing artificial consciousness, the failure of any particular test would not disprove consciousness. Also statistical methods should be used for testing when there is an uncertain outcome.
The most well-known method for testing machine intelligence, the Turing test, may be seen as an indirect test for consciousness. No machine has yet passed the test though. As the test is purely behavioral, it is possible that a conscious machine would fail through lack of intelligence, for example.
Main article: Turing test

[edit] The ethics of artificial consciousness
Main article: ethics of artificial intelligence
If it was certain that a particular machine was conscious its rights would be an ethical issue that would need to be assessed (e.g. what rights it would have under law). For example a conscious computer that was owned and used as a tool or central computer of a building or large machine is a particular ambiguity. Should laws be made for such a case, consciousness would also require a legal definition (for example a machine's ability to experience pleasure or pain, known as sentience). Because artificial consciousness is still largely a theoretical subject such ethics have not been discussed or developed to a great extent, though it has often been a theme in fiction (see below).
The rules for the 2003 Loebner Prize competition explicitly addressed the question of robot rights:

61. If, in any given year, a publicly available open source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right.[3]


[edit] Artificial consciousness in literature and movies
Main article: artificial intelligence in fiction

Vanamonde in Arthur C. Clarke's The City and the Stars
The Ship (the result of a large-scale AC experiment) in Frank Herbert's Destination: Void and sequels, despite past edicts warning against "Making a Machine in the Image of a Man's Mind."
Jane in Orson Scott Card's Speaker for the Dead, Xenocide, Children of the Mind, and Investment Counselor
HAL 9000 in 2001: A Space Odyssey
Robots in Isaac Asimov's Robot Series
The Minds in Iain M. Bank's Culture novels.
The Sentient Intelligence in Peter F. Hamilton's Commonwealth Saga and sequel.
Many of Robert A. Heinlein's short stories and novels feature AI/AC plots and discussion. See The Moon Is a Harsh Mistress, Time Enough for Love, The Number of the Beast.


[edit] See also

Artificial Intelligence
Brain-computer interface
Greedy reductionism
Homunculus fallacy
Identity of indiscernibles
Jabberwacky
Kismet (robot)
Morgan's Canon
Philosophy of mind
Psi-Theory
Strong AI
William Grey Walter


[edit] References


^ Aleksander I (1996) Impossible Minds: My neurons, My Consciousness, Imperial College Press ISBN 1-86094-036-6
^ Wilson RJ (1998) review of Impossible Minds. Journal of Consciousness Studies 5(1), 115-6.
^ Loebner Prize Contest Official Rules — Version 2.0 The competition was directed by David Hamill and the rules were developed by members of the Robitron Yahoo group.



Aleksander, Igor (1995), Artificial Neuroconsciousness: An Update, IWANN  BibTex Internet Archive
Baars, Bernard (1988), A Cognitive Theory of Consciousness, Cambridge, MA: Cambridge University Press, http://vesicle.nsi.edu/users/baars/BaarsConsciousnessBook1988 
Baars, Bernard (1997), In the Theater of Consciousness, New York, NY: Oxford University Press 
Chalmers, David (1996), The Conscious Mind, Oxford University Press. 
Cotterill, Rodney (2003), "Cyberchild: a Simulation Test-Bed for Consciousness Studies", in Holland, Owen, Machine Consciousness, Imprint Academic 
Franklin, Stan (1995), Artificial Minds, Boston, MA: MIT Press 
Franklin, Stan (2003), "IDA: A Conscious Artefact", in Holland, Owen, Machine Consciousness, Exeter, UK: Imprint Academic 
Freeman, Walter (1999), How Brains make up their Minds, Phoenix 
Haikonen, Pentti (2003), The Cognitive Approach to Conscious Machines, Imprint Academic 
Sanz, Ricardo (2007), "Principles for consciousness in integrated cognitive control", Neural Networks 20 
Sun, Ron (December 1999), "Accounting for the computational basis of consciousness: A connectionist approach", Consciousness and Cognition 8 
Sun, Ron (2001), "Computation, reduction, and teleology of consciousness", Cognitive Systems Research 1 (4): 241-249 
Takeno, Junichi; Inaba, K; Suzuki, T. (June 27-30, 2005), "Experiments and examination of mirror image cognition using a small robot", The 6th IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA 2005): 493-498, http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1554325 
Cleeremans, Axel (2001), Implicit learning and consciousness, http://srsc.ulb.ac.be/axcWWW/papers/pdf/01-AXCLJ.pdf 


[edit] Further reading

Haikonen, Pentti (2004), Conscious Machines and Machine Emotions, presented at Workshop on Models for Machine Consciousness, Antwerp, BE, June 2004.
Baars, Bernard J and Stan Franklin. 2003. How conscious experience and working memory interact. Trends in Cognitive Science 7: 166–172.
Franklin, S, B J Baars, U Ramamurthy, and Matthew Ventura. 2005. The role of consciousness in memory. Brains, Minds and Media 1: 1–38, pdf.
Casti, John L. "The Cambridge Quintet: A Work of Scientific Speculation", Perseus Books Group , 1998
McCarthy, John (1971-1987), Generality in Artificial Intelligence [6]. Stanford University, 1971-1987.
Pharoah M.C. (online). Looking to systems theory for a reductive explanation of phenomenal experience and evolutionary foundations for higher order thought Retrieved Dec. 13, 2007.
Suzuki T., Inaba K., Takeno, Junichi (2005), Conscious Robot That Distinguishes Between Self and Others and Implements Imitation Behavior, ( Best Paper of IEA/AIE2005), Innovations in Applied Artificial Intelligence, 18th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, pp. 101-110, IEA/AIE 2005, Bari, Italy, June 22-24, 2005.
Takeno, Junichi (2006), The Self-Aware Robot -A Response to Reactions to Discovery News- [7], HRI Press, August 2006.
Sternberg, Eliezer J. (2007) Are You a Machine? Tha Brain the Mind and What it Means to be Human. Amherst, NY: Prometheus Books.
Wikibook on consciousness
Site of Steven Ericsson-Zenith's Explaining Experience in Nature information site.


[edit] External links

Ron Sun's papers on consciousness
Humanoid Robotics Ethical Considerations
Scientific Ethics
Artefactual consciousness depiction by Professor Igor Aleksander
David Chalmers
Online papers on the possible mechanisms of Higher-Order Thought
ESF Models of Consciousness Workshop and its Scientific Report
Machine Consciousness - Complexity Aspects Workshop
Robot In Touch with Its Emotions 5-Sep-2005
Robot Demonstrates Self-awareness 21-Dec-2005
www.Conscious-Robots.com - Portal dedicated to Machine Consciousness


[edit] Open Source Software Projects

ADS-AC -- An experimental Open Source program which implements Absolutely Dynamic System, a proposed mechanism for AC




Retrieved from "http://en.wikipedia.org/wiki/Artificial_consciousness"
Categories: Artificial intelligence | Philosophy of mind | Consciousness studiesHidden categories: Cleanup from September 2007 | All pages needing cleanup | Philosophy articles needing expert attention | Articles needing expert attention since November 2008 






Views


Article
Discussion
Edit this page
History 



Personal tools


Log in / create account






 if (window.isMSIE55) fixalpha(); 

Navigation


Main page
Contents
Featured content
Current events
Random article




Search




 
				




Interaction


About Wikipedia
Community portal
Recent changes
Contact Wikipedia
Donate to Wikipedia
Help




Toolbox


What links here
Related changes
Upload file
Special pages
Printable version Permanent linkCite this page 



Languages


日本語
Suomi
اردو









 This page was last modified on 24 March 2009, at 00:32 (UTC).
All text is available under the terms of the GNU Free Documentation License. (See Copyrights for details.)  Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit charity.
Privacy policy
About Wikipedia
Disclaimers



if (window.runOnloadHook) runOnloadHook();
